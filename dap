#!/bin/bash

#######################################################################################
# DAP Application Manager - All-in-One Script
# 
# Manages the complete DAP (Database Application Platform) lifecycle:
# - Application start/stop/restart/status
# - Database cleanup and sample data setup  
# - Browser cache clearing guidance
# - Development environment management
#
# Usage: ./dap [command]
# Commands: start, stop, restart, status, reset, clean-restart, rebuild, add-sample, reset-sample, help
# Testing: Use ./dap-test for all test commands (e2e, unit, tags, integration)
#######################################################################################

set -e

# Configuration - Load from environment or use defaults
APP_NAME="DAP Application"
BACKEND_PORT="${BACKEND_PORT:-4000}"
DEVTOOLS_PORT="${DEVTOOLS_PORT:-4001}"
FRONTEND_PORT="${FRONTEND_PORT:-5173}"
# Use the directory of this script as the project root
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$SCRIPT_DIR"
BACKEND_DIR="$PROJECT_DIR/backend"
FRONTEND_DIR="$PROJECT_DIR/frontend"

# Platform-aware mode selection
OS_NAME="$(uname -s)"
HOSTNAME_LOWER="$(hostname | tr '[:upper:]' '[:lower:]' || echo 'unknown')"

DEFAULT_DAP_MODE="linux-dev"

# Auto-detect environment
if [ "$OS_NAME" = "Darwin" ]; then
    DEFAULT_DAP_MODE="mac-demo"
elif [[ "$HOSTNAME_LOWER" == *"centos2"* ]]; then
    DEFAULT_DAP_MODE="production"
elif [[ "$HOSTNAME_LOWER" == *"centos1"* ]]; then
    DEFAULT_DAP_MODE="linux-dev"
fi

DAP_MODE="${DAP_MODE:-$DEFAULT_DAP_MODE}"

# Production mode delegation
if [ "$DAP_MODE" = "production" ]; then
    if [ -x "$PROJECT_DIR/dap-prod" ]; then
        exec "$PROJECT_DIR/dap-prod" "$@"
    else
        echo -e "\033[0;31m[ERROR] Production manager script (dap-prod) not found or not executable.\033[0m" >&2
        exit 1
    fi
fi
MAC_DEPLOY_SCRIPT="$PROJECT_DIR/scripts/mac-light-deploy.sh"

# Dependency checks - Docker only required for linux-dev mode
REQUIRED_DEPS="node npm lsof pkill"
if [ "$DAP_MODE" = "linux-dev" ]; then
    REQUIRED_DEPS="docker $REQUIRED_DEPS"
fi

for dep in $REQUIRED_DEPS; do
    if ! command -v $dep >/dev/null 2>&1; then
        echo "[ERROR] Required dependency '$dep' is not installed or not in PATH. Please install it before running this script."
        exit 1
    fi
done

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Logging functions
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_header() { echo -e "${PURPLE}=== $1 ===${NC}"; }

use_mac_mode() {
    [ "$DAP_MODE" = "mac-demo" ]
}

ensure_mac_script() {
    if [ ! -x "$MAC_DEPLOY_SCRIPT" ]; then
        log_error "Mac deploy script not found or not executable: $MAC_DEPLOY_SCRIPT"
        exit 1
    fi
}

mac_start() {
    ensure_mac_script
    log_header "STARTING MAC LIGHT PROD MODE"
    "$MAC_DEPLOY_SCRIPT" start
}

mac_stop() {
    ensure_mac_script
    log_header "STOPPING MAC LIGHT PROD MODE"
    "$MAC_DEPLOY_SCRIPT" stop
}

mac_restart() {
    ensure_mac_script
    log_header "RESTARTING MAC LIGHT PROD MODE"
    "$MAC_DEPLOY_SCRIPT" restart
}

mac_status() {
    ensure_mac_script
    log_header "STATUS - MAC LIGHT PROD MODE"
    "$MAC_DEPLOY_SCRIPT" status
}

mac_reset() {
    ensure_mac_script
    log_header "RESETTING DATABASE - MAC LIGHT PROD MODE"
    "$MAC_DEPLOY_SCRIPT" reset
}

# Check if a port is in use
check_port() {
    local port=$1
    lsof -Pi :$port -sTCP:LISTEN -t >/dev/null 2>&1
}

# Kill processes on a specific port
kill_port() {
    local port=$1
    local service_name=$2
    
    if check_port $port; then
        log_info "Stopping $service_name on port $port..."
        local pids=$(lsof -Pi :$port -sTCP:LISTEN -t 2>/dev/null || true)
        if [ ! -z "$pids" ]; then
            echo "$pids" | xargs kill -TERM 2>/dev/null || true
            sleep 2
            local remaining_pids=$(lsof -Pi :$port -sTCP:LISTEN -t 2>/dev/null || true)
            if [ ! -z "$remaining_pids" ]; then
                echo "$remaining_pids" | xargs kill -KILL 2>/dev/null || true
            fi
            log_success "$service_name stopped"
        fi
    else
        log_info "$service_name not running on port $port"
    fi
}

# Kill Node.js processes related to the project
# Stop backend only
stop_backend() {
    log_info "Stopping Backend..."
    pkill -f "ts-node-dev.*src/server.ts" 2>/dev/null || true
    pkill -f "npm.*exec.*ts-node-dev" 2>/dev/null || true
    pkill -f "node.*backend.*server" 2>/dev/null || true
    kill_port $BACKEND_PORT "Backend API"
}

# Stop frontend only
stop_frontend() {
    log_info "Stopping Frontend..."
    pkill -f "vite.*--port.*5173" 2>/dev/null || true
    pkill -f "npm.*exec.*vite" 2>/dev/null || true
    pkill -f "node.*frontend.*vite" 2>/dev/null || true
    kill_port $FRONTEND_PORT "Frontend Dev Server"
}

# Stop devtools only
stop_devtools() {
    log_info "Stopping DevTools..."
    pkill -f "ts-node-dev.*src/devtools-service.ts" 2>/dev/null || true
    kill_port $DEVTOOLS_PORT "DevTools Server"
}

# Kill Node.js processes related to the project
kill_node_processes() {
    log_info "Stopping all Node.js processes related to the project..."
    stop_backend
    stop_frontend
    stop_devtools
    log_success "Node.js processes stopped"
}

# Force kill all DAP-related processes (more aggressive)
force_kill_all() {
    log_warning "Force killing all DAP-related processes..."
    
    # Kill by process name patterns
    pkill -9 -f "ts-node-dev.*src/server.ts" 2>/dev/null || true
    pkill -9 -f "vite.*--port.*5173" 2>/dev/null || true
    pkill -9 -f "npm.*exec.*ts-node-dev" 2>/dev/null || true
    pkill -9 -f "npm.*exec.*vite" 2>/dev/null || true
    pkill -9 -f "node.*backend.*server" 2>/dev/null || true
    pkill -9 -f "node.*frontend.*vite" 2>/dev/null || true
    
    # Force kill any remaining processes on the ports
    if check_port $BACKEND_PORT; then
        local pids=$(lsof -Pi :$BACKEND_PORT -sTCP:LISTEN -t 2>/dev/null || true)
        if [ ! -z "$pids" ]; then
            log_info "Force killing backend processes on port $BACKEND_PORT: $pids"
            echo "$pids" | xargs kill -9 2>/dev/null || true
        fi
    fi
    
    if check_port $FRONTEND_PORT; then
        local pids=$(lsof -Pi :$FRONTEND_PORT -sTCP:LISTEN -t 2>/dev/null || true)
        if [ ! -z "$pids" ]; then
            log_info "Force killing frontend processes on port $FRONTEND_PORT: $pids"
            echo "$pids" | xargs kill -9 2>/dev/null || true
        fi
    fi
    
    # Give the system a moment to clean up
    sleep 2
    
    # Verify ports are clear
    if check_port $BACKEND_PORT; then
        log_error "Backend port $BACKEND_PORT still in use after force kill"
        lsof -Pi :$BACKEND_PORT
    else
        log_success "Backend port $BACKEND_PORT is clear"
    fi
    
    if check_port $FRONTEND_PORT; then
        log_error "Frontend port $FRONTEND_PORT still in use after force kill"
        lsof -Pi :$FRONTEND_PORT
    else
        log_success "Frontend port $FRONTEND_PORT is clear"
    fi
    
    log_success "Force kill complete"
}

# Manage Docker containers (linux-dev mode only)
manage_docker() {
    local action=$1
    
    # Get DB container name dynamically (only when docker is available)
    local DB_CONTAINER
    DB_CONTAINER="$(docker ps -a --format '{{.Names}}' 2>/dev/null | grep -E '^dap[-_]db[-_]1$|^dap_db_1$|^dap-db-1$|^db$' | head -n 1)"
    
    case $action in

        start)
            log_info "Starting PostgreSQL database container..."
            if docker ps -a --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                if docker ps --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                    log_info "Database container already running"
                else
                    docker start $DB_CONTAINER
                    log_success "Database container started"
                fi
            else
                log_warning "Database container $DB_CONTAINER not found. Attempting to create it with 'docker compose up -d db'..."
                (cd "$PROJECT_DIR" && docker compose up -d db)
                # Wait for container to appear
                local max_attempts=10
                local attempt=1
                while [ $attempt -le $max_attempts ]; do
                    if docker ps -a --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                        log_success "Database container $DB_CONTAINER created"
                        break
                    fi
                    sleep 1
                    ((attempt++))
                done
                if ! docker ps -a --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                    log_error "Failed to create database container $DB_CONTAINER. Please check your docker-compose.yml."
                    return 1
                fi
            fi
            
            log_info "Waiting for database to be ready..."
            local max_attempts=30
            local attempt=1
            
            while [ $attempt -le $max_attempts ]; do
                if docker exec $DB_CONTAINER pg_isready -U dap >/dev/null 2>&1; then
                    log_success "Database is ready"
                    break
                fi
                
                if [ $attempt -eq $max_attempts ]; then
                    log_error "Database failed to become ready within 30 seconds"
                    return 1
                fi
                
                echo -n "."
                sleep 1
                ((attempt++))
            done
            ;;
            
        stop)
            log_info "Stopping PostgreSQL database container..."
            if docker ps --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                docker stop $DB_CONTAINER
                log_success "Database container stopped"
            else
                log_info "Database container not running"
            fi
            ;;
            
        status)
            if docker ps --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                log_success "Database container is running"
                docker exec $DB_CONTAINER pg_isready -U dap >/dev/null 2>&1 && log_success "Database is accepting connections"
            elif docker ps -a --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                log_warning "Database container exists but is not running"
            else
                log_error "Database container not found"
            fi
            ;;
            
        restart)
            log_info "Restarting PostgreSQL database (clearing all connections)..."
            if docker ps --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                docker restart $DB_CONTAINER
                log_success "Database container restarted"
                
                # Wait for database to be ready again
                log_info "Waiting for database to be ready..."
                local max_attempts=30
                local attempt=1
                while [ $attempt -le $max_attempts ]; do
                    if docker exec $DB_CONTAINER pg_isready -U dap >/dev/null 2>&1; then
                        log_success "Database is ready and accepting new connections"
                        break
                    fi
                    if [ $attempt -eq $max_attempts ]; then
                        log_error "Database failed to become ready within 30 seconds"
                        return 1
                    fi
                    echo -n "."
                    sleep 1
                    ((attempt++))
                done
            else
                log_warning "Database container not running, starting it..."
                manage_docker start
            fi
            ;;
    esac
}

# Start backend
start_backend() {
    log_info "Starting Backend GraphQL API..."
    
    if check_port $BACKEND_PORT; then
        log_warning "Backend already running on port $BACKEND_PORT"
        return 0
    fi
    
    cd "$BACKEND_DIR"
    
    if [ ! -d "node_modules" ]; then
        log_info "Installing backend dependencies..."
        npm install
    fi
    
    log_info "Starting backend server on port $BACKEND_PORT..."
    nohup npm run dev > ../backend.log 2>&1 &
    local backend_pid=$!
    
    local max_attempts=60
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        if check_port $BACKEND_PORT; then
            log_success "Backend API started successfully (PID: $backend_pid)"
            return 0
        fi
        
        if [ $attempt -eq $max_attempts ]; then
            log_error "Backend failed to start within 20 seconds"
            return 1
        fi
        
        echo -n "."
        sleep 1
        ((attempt++))
    done
}

# Start frontend
start_frontend() {
    log_info "Starting Frontend React App..."
    
    if check_port $FRONTEND_PORT; then
        log_warning "Frontend already running on port $FRONTEND_PORT"
        return 0
    fi
    
    cd "$FRONTEND_DIR"
    
    if [ ! -d "node_modules" ]; then
        log_info "Installing frontend dependencies..."
        npm install
    fi
    
    log_info "Starting frontend dev server on port $FRONTEND_PORT..."
    
    # Export Vite environment variables from .env if available
    # This ensures VITE_BASE_PATH is set correctly for dev server (e.g., /dap/ for subpath deployments)
    if [ -f "$PROJECT_DIR/.env" ]; then
        local vite_base_path=$(grep "^VITE_BASE_PATH=" "$PROJECT_DIR/.env" 2>/dev/null | cut -d '=' -f2- || echo "/")
        local vite_gql_endpoint=$(grep "^VITE_GRAPHQL_ENDPOINT=" "$PROJECT_DIR/.env" 2>/dev/null | cut -d '=' -f2- || echo "/graphql")
        export VITE_BASE_PATH="${vite_base_path:-/}"
        export VITE_GRAPHQL_ENDPOINT="${vite_gql_endpoint:-/graphql}"
        log_info "Using VITE_BASE_PATH=$VITE_BASE_PATH"
    fi
    
    nohup npm run dev > ../frontend.log 2>&1 &
    local frontend_pid=$!
    
    local max_attempts=60
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        if check_port $FRONTEND_PORT; then
            log_success "Frontend dev server started successfully (PID: $frontend_pid)"
            log_success "Frontend available at: http://localhost:$FRONTEND_PORT"
            return 0
        fi
        
        if [ $attempt -eq $max_attempts ]; then
            log_error "Frontend failed to start within 30 seconds"
            return 1
        fi
        
        echo -n "."
        sleep 1
        ((attempt++))
    done
}

# Start devtools
start_devtools() {
    log_header "DEVTOOLS SERVER"
    log_info "Starting DevTools Server..."
    
    if check_port $DEVTOOLS_PORT; then
        log_warning "DevTools already running on port $DEVTOOLS_PORT"
        return 0
    fi
    
    cd "$BACKEND_DIR"
    
    log_info "Starting devtools server on port $DEVTOOLS_PORT..."
    nohup npm run dev:devtools > ../devtools.log 2>&1 &
    local devtools_pid=$!
    
    local max_attempts=20
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        if check_port $DEVTOOLS_PORT; then
            log_success "DevTools Server started successfully (PID: $devtools_pid)"
            log_success "DevTools available at: http://localhost:$DEVTOOLS_PORT/api/dev"
            return 0
        fi
        
        if [ $attempt -eq $max_attempts ]; then
            log_error "DevTools failed to start within 20 seconds. Check devtools.log"
            return 1
        fi
        
        echo -n "."
        sleep 1
        ((attempt++))
    done
}

# Show application status
show_status() {
    log_header "APPLICATION STATUS"
    
    echo -e "${CYAN}Database (PostgreSQL):${NC}"
    manage_docker status
    
    echo -e "\n${CYAN}Backend API (GraphQL):${NC}"
    if check_port $BACKEND_PORT; then
        log_success "Backend running on port $BACKEND_PORT"
        log_info "API endpoint: http://localhost:$BACKEND_PORT/graphql"
    else
        log_error "Backend not running on port $BACKEND_PORT"
    fi
    
    echo -e "\n${CYAN}Frontend (React/Vite):${NC}"
    if check_port $FRONTEND_PORT; then
        log_success "Frontend running on port $FRONTEND_PORT"
        log_info "Web interface: http://localhost:$FRONTEND_PORT"
    else
        log_error "Frontend not running on port $FRONTEND_PORT"
    fi
    
    echo -e "\n${CYAN}Quick Database Check:${NC}"
    if check_port $BACKEND_PORT && docker exec $DB_CONTAINER pg_isready -U dap >/dev/null 2>&1; then
        local product_count=$(docker exec $DB_CONTAINER psql -U dap -d dap -t -c "SELECT COUNT(*) FROM \"Product\";" 2>/dev/null | tr -d ' ')
        local task_count=$(docker exec $DB_CONTAINER psql -U dap -d dap -t -c "SELECT COUNT(*) FROM \"Task\";" 2>/dev/null | tr -d ' ')
        log_info "Database contains: $product_count products, $task_count tasks"
    else
        log_warning "Cannot check database content (database not accessible)"
    fi
}

# Clean database and add sample data
clean_database() {
    log_header "CLEAN DATABASE SETUP"
    log_warning "âš ï¸  This will DELETE ALL existing data including user-created products!"
    log_warning "âš ï¸  All products, solutions, customers, and relationships will be removed!"
    echo ""
    
    log_info "Cleaning database..."
    
    # Clean all tables
    # Ensure the database container is running
    if ! docker ps --format '{{.Names}}' | grep -q "^$DB_CONTAINER$"; then
        log_error "Database container $DB_CONTAINER is not running. Please start it with 'docker compose up -d db'."
        return 1
    fi

    # Wait for database to be healthy
    local max_attempts=30
    local attempt=1
    while [ $attempt -le $max_attempts ]; do
        if docker exec $DB_CONTAINER pg_isready -U dap >/dev/null 2>&1; then
            break
        fi
        sleep 1
        ((attempt++))
    done
    if ! docker exec $DB_CONTAINER pg_isready -U dap >/dev/null 2>&1; then
        log_error "Database is not ready after waiting. Please check the container logs."
        return 1
    fi

    # Clean tables (in proper order to handle foreign key constraints)
    # Based on actual Prisma schema models - deleting from most dependent to least
    docker exec $DB_CONTAINER psql -U dap -d dap -c "
      -- Level 1: Deepest dependencies (telemetry values, task relationships)
      DELETE FROM \"CustomerTelemetryValue\";
      DELETE FROM \"TelemetryValue\";
      DELETE FROM \"CustomerTaskOutcome\";
      DELETE FROM \"CustomerTaskRelease\";
      
      -- Level 2: Customer adoption tasks and telemetry attributes
      DELETE FROM \"CustomerTelemetryAttribute\";
      DELETE FROM \"CustomerSolutionTask\";
      DELETE FROM \"CustomerTask\";
      DELETE FROM \"TelemetryAttribute\";
      
      -- Level 3: Solution and product adoption plans
      DELETE FROM \"SolutionAdoptionProduct\";
      DELETE FROM \"SolutionAdoptionPlan\";
      DELETE FROM \"AdoptionPlan\";
      
      -- Level 4: Customer assignments (solutions and products)
      DELETE FROM \"CustomerSolution\";
      DELETE FROM \"CustomerProduct\";
      
      -- Level 5: Junction tables (must be before parent tables)
      DELETE FROM \"SolutionProduct\";
      DELETE FROM \"SolutionTaskOrder\";
      DELETE FROM \"TaskOutcome\";
      DELETE FROM \"TaskRelease\";
      
      -- Level 6: Core entities (tasks, outcomes, licenses, releases)
      DELETE FROM \"Task\";
      DELETE FROM \"Outcome\";
      DELETE FROM \"License\";
      DELETE FROM \"Release\";
      DELETE FROM \"CustomAttribute\";
      DELETE FROM \"Telemetry\";
      
      -- Level 7: Top-level entities (products, solutions, customers)
      DELETE FROM \"Product\";
      DELETE FROM \"Solution\";
      DELETE FROM \"Customer\";
      
      -- Level 8: Audit, change tracking, and system tables
      DELETE FROM \"ChangeItem\";
      DELETE FROM \"ChangeSet\";
      DELETE FROM \"AuditLog\";
      DELETE FROM \"LockedEntity\";
      DELETE FROM \"Session\";
      
      -- Note: User table intentionally NOT deleted to preserve admin accounts
    " 2>&1 | tee /tmp/dap_db_cleanup.log
    if grep -qE 'ERROR|FATAL' /tmp/dap_db_cleanup.log; then
        log_error "Failed to clean database tables. See /tmp/dap_db_cleanup.log for details."
        cat /tmp/dap_db_cleanup.log
        return 1
    fi
    log_success "Database cleaned"

    log_info "Creating 5 Cisco products with full attributes..."
    log_info "Loading enhanced Cisco sample data from SQL file..."
    
    # Execute the comprehensive sample data SQL file (showing errors for debugging)
    if ! docker exec -i $DB_CONTAINER psql -U dap -d dap < "$PROJECT_DIR/create-complete-sample-data.sql" 2>&1 | tee /tmp/dap_sample_load.log; then
        log_error "Failed to create complete sample data."
        log_error "Check /tmp/dap_sample_load.log for details"
        cat /tmp/dap_sample_load.log
        return 1
    fi
    
    # Check for SQL errors
    if grep -qE 'ERROR|FATAL' /tmp/dap_sample_load.log; then
        log_error "SQL errors detected during sample data creation"
        grep -E 'ERROR|FATAL' /tmp/dap_sample_load.log
        return 1
    fi
    
    log_success "Complete sample data created successfully!"

    # Verify what was created
    local products=$(docker exec $DB_CONTAINER psql -U dap -d dap -t -c "SELECT COUNT(*) FROM \"Product\";" 2>/dev/null | tr -d ' ')
    local tasks=$(docker exec $DB_CONTAINER psql -U dap -d dap -t -c "SELECT COUNT(*) FROM \"Task\";" 2>/dev/null | tr -d ' ')
    local licenses=$(docker exec $DB_CONTAINER psql -U dap -d dap -t -c "SELECT COUNT(*) FROM \"License\";" 2>/dev/null | tr -d ' ')
    local outcomes=$(docker exec $DB_CONTAINER psql -U dap -d dap -t -c "SELECT COUNT(*) FROM \"Outcome\";" 2>/dev/null | tr -d ' ')
    local solutions=$(docker exec $DB_CONTAINER psql -U dap -d dap -t -c "SELECT COUNT(*) FROM \"Solution\";" 2>/dev/null | tr -d ' ')
    local customers=$(docker exec $DB_CONTAINER psql -U dap -d dap -t -c "SELECT COUNT(*) FROM \"Customer\";" 2>/dev/null | tr -d ' ')
    
    log_info "Created comprehensive Cisco sample data:"
    log_info "  ğŸ“¦ $products Products (Duo, SD-WAN, Secure Firewall, ISE, Secure Access Sample)"
    log_info "  ğŸ“‹ $tasks Tasks (10-15 tasks per product with full attributes)"
    log_info "  ğŸ·ï¸ $licenses Licenses (Essential, Advantage, Signature/Premier/Beyond tiers)"
    log_info "  ğŸ¯ $outcomes Outcomes (Security, performance, and compliance metrics)"
    log_info "  ğŸ¯ $solutions Solutions (Hybrid Private Access, SASE)"
    log_info "  ğŸ¢ $customers Customers (ACME and Chase)"
    
    # Note: Solutions are already created in the SQL file above
    # No need to run npm run seed here as it would duplicate data
}

# Development Mode (Interactive)
dev_mode() {
    log_header "STARTING DEVELOPMENT ENVIRONMENT"
    
    # 1. Start Database
    manage_docker start || exit 1
    
    # 2. Install Dependencies if needed
    if [ ! -d "$BACKEND_DIR/node_modules" ]; then
        log_info "Installing backend dependencies..."
        (cd "$BACKEND_DIR" && npm install)
    fi
    if [ ! -d "$FRONTEND_DIR/node_modules" ]; then
        log_info "Installing frontend dependencies..."
        (cd "$FRONTEND_DIR" && npm install)
    fi
    
    # 3. Run Migrations
    log_info "Running database migrations..."
    (cd "$BACKEND_DIR" && npx prisma migrate deploy) || log_warning "Migration failed, continuing..."
    
    # 3.5 Seed Development Data (only if explicitly requested)
    if [ "${SEED_ON_RESTART:-false}" = "true" ]; then
        log_info "Seeding development data..."
        (cd "$BACKEND_DIR" && npm run seed:dev) || log_warning "Seeding failed, continuing..."
    else
        log_info "Skipping seed (set SEED_ON_RESTART=true to enable)"
    fi
    
    # 4. Start Services in Foreground
    log_info "Starting services in development mode..."
    log_info "Press Ctrl+C to stop all services"
    echo ""
    
    # Kill any existing processes first
    kill_node_processes
    
    # Trap Ctrl+C
    trap 'trap - INT TERM EXIT; echo ""; log_warning "Stopping development environment..."; kill 0' INT TERM EXIT
    
    # Start Backend
    (cd "$BACKEND_DIR" && npm run dev 2>&1 | sed "s/^/${BLUE}[BACKEND]${NC} /") &
    
    # Start Frontend
    (cd "$FRONTEND_DIR" && npm run dev 2>&1 | sed "s/^/${GREEN}[FRONTEND]${NC} /") &
    
    # Wait for all background processes
    wait
}

# Start all services
start_all() {
    log_header "STARTING $APP_NAME"
    
    # Sync development environment files
    if [ ! -f "$PROJECT_DIR/.env" ]; then
        if [ -f "$PROJECT_DIR/.env.example" ]; then
             log_warning "No .env found. Creating from .env.example..."
             cp "$PROJECT_DIR/.env.example" "$PROJECT_DIR/.env"
             log_warning "Please edit .env with your configuration!"
        fi
    fi

    if [ -f "$PROJECT_DIR/.env" ]; then
        log_info "Syncing environment..."
        cp "$PROJECT_DIR/.env" "$BACKEND_DIR/.env"
        cp "$PROJECT_DIR/.env" "$FRONTEND_DIR/.env"
        log_success "Environment synced from .env"
    fi
    
    manage_docker start || exit 1
    
    # Run Migrations (only if requested)
    if [ "${RUN_MIGRATIONS:-false}" = "true" ]; then
        log_info "Running database migrations..."
        (cd "$BACKEND_DIR" && npx prisma migrate deploy) || log_warning "Migration failed, continuing..."
    fi

    # Seed Development Data (only if explicitly requested)
    if [ "${SEED_ON_RESTART:-false}" = "true" ]; then
        log_info "Seeding development data..."
        (cd "$BACKEND_DIR" && npm run seed:dev) || log_warning "Seeding failed, continuing..."
    fi

    start_backend || exit 1
    start_devtools || exit 1
    start_frontend || exit 1
    
    echo ""
    log_success "All services started successfully!"
    log_info "Database: PostgreSQL running in container"
    log_info "Backend API: http://localhost:$BACKEND_PORT/graphql"
    log_info "Frontend App: http://localhost:$FRONTEND_PORT"
    
    # Ensure admin user exists and credentials are correct
    if [ -x "$PROJECT_DIR/scripts/ensure-admin-user.sh" ]; then
        echo ""
        "$PROJECT_DIR/scripts/ensure-admin-user.sh"
    fi
}

# Restart devtools only
restart_devtools() {
    log_header "RESTARTING DEVTOOLS"
    stop_devtools
    sleep 1
    start_devtools
}

# Start services without migrations or seeding
start_services() {
    log_header "STARTING SERVICES"

    # Mac demo runs via the mac light deploy script (no Docker)
    if use_mac_mode; then
        mac_start
        return
    fi

    manage_docker start || exit 1

    start_backend || exit 1
    start_devtools || exit 1
    start_frontend || exit 1

    echo ""
    log_success "Services started successfully!"
    log_info "Database: PostgreSQL running in container"
    log_info "Backend API: http://localhost:$BACKEND_PORT/graphql"
    log_info "Frontend App: http://localhost:$FRONTEND_PORT"
}

# Stop all services
stop_all() {
    log_header "STOPPING $APP_NAME"
    
    kill_node_processes
    manage_docker stop
    docker stop $(docker ps -q --filter "name=dap_") 2>/dev/null || true
    
    log_success "All services stopped"
}

# Restart all services
restart_all() {
    log_header "RESTARTING $APP_NAME"
    
    # Use force kill for restart to ensure clean shutdown
    force_kill_all
    manage_docker stop
    
    echo ""
    sleep 3
    
    start_all
    
    echo ""
    log_header "BROWSER CACHE CLEARING"
    log_warning "If GUI still shows old data, clear your browser cache:"
    log_info "1. Press Ctrl+Shift+R (hard refresh)"
    log_info "2. Or open Private/Incognito window: Ctrl+Shift+N"
    log_info "3. Visit: http://localhost:$FRONTEND_PORT"
}

# Helper function to check if backend is running
check_backend_running() {
    lsof -ti:$BACKEND_PORT >/dev/null 2>&1
}

# Helper function to check if frontend is running
check_frontend_running() {
    lsof -ti:$FRONTEND_PORT >/dev/null 2>&1
}

# Run comprehensive E2E test (same as GUI)
run_comprehensive_test() {
    log_header "COMPREHENSIVE E2E TEST (Shadow Database)"
    
    echo ""
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${CYAN}ğŸ§ª DAP Comprehensive E2E Test - Shadow Database Mode${NC}"
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    log_info "ğŸ“ Working Directory: $BACKEND_DIR"
    log_info "ğŸ—ƒï¸  Database: dap_test (shadow copy - dev data protected!)"
    log_info "ğŸ”§ NODE_ENV: test"
    log_info "ğŸ” Test: comprehensive-crud (38 tests)"
    echo ""
    
    # Ensure test database exists
    log_info "â³ Ensuring test database exists..."
    
    if use_mac_mode; then
        # Mac: Use local psql (Homebrew PostgreSQL)
        local current_user=$(whoami)
        if ! psql -h localhost -p 5432 -lqt 2>/dev/null | cut -d \| -f 1 | grep -qw 'dap_test'; then
            log_info "ğŸ“ Creating test database..."
            createdb -h localhost -p 5432 dap_test 2>/dev/null || true
        fi
        log_success "âœ… Test database ready"
        
        echo ""
        log_info "ğŸ’» Command (Mac mode):"
        echo "   cd $BACKEND_DIR && DATABASE_URL=postgresql://${current_user}@localhost:5432/dap_test npm test -- --runInBand --passWithNoTests --testPathPattern=\"comprehensive-crud\""
        echo ""
        echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
        echo ""
        
        # Run E2E test with shadow database (Mac)
        cd "$BACKEND_DIR"
        
        export DATABASE_URL="postgresql://${current_user}@localhost:5432/dap_test?schema=public"
        
        # Run migrations on test database
        log_info "ğŸ”„ Running migrations on test database..."
        npx prisma migrate deploy --skip-generate 2>/dev/null || npx prisma db push --skip-generate 2>/dev/null || true
        log_success "âœ… Test database schema ready"
    else
        # Linux: Use Docker
        if ! docker exec $DB_CONTAINER psql -U postgres -c '\l' 2>/dev/null | grep -q 'dap_test'; then
            log_info "ğŸ“ Creating test database..."
            docker exec $DB_CONTAINER psql -U postgres -c "CREATE DATABASE dap_test;" 2>/dev/null || true
        fi
        log_success "âœ… Test database ready"
        
        echo ""
        log_info "ğŸ’» Command (identical to GUI):"
        echo "   cd $BACKEND_DIR && DATABASE_URL=postgres://postgres:postgres@localhost:5432/dap_test npm test -- --runInBand --passWithNoTests --testPathPattern=\"comprehensive-crud\""
        echo ""
        echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
        echo ""
        
        # Run E2E test with shadow database (Linux)
        cd "$BACKEND_DIR"
        
        export DATABASE_URL="postgres://postgres:postgres@localhost:5432/dap_test?schema=public"
    fi
    export NODE_ENV="test"
    export CI="true"
    
    if npm test -- --runInBand --passWithNoTests --testPathPattern="comprehensive-crud"; then
        echo ""
        echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        log_success "ğŸ‰ COMPREHENSIVE E2E TEST PASSED!"
        echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        echo ""
        log_info "All 38 tests passed:"
        log_info "âœ… Product CRUD (create, read, update, delete, outcomes, releases, licenses)"
        log_info "âœ… Task CRUD (create, read, update, delete, telemetry, reorder)"
        log_info "âœ… Solution CRUD (create, read, update, add/remove products)"
        log_info "âœ… Customer CRUD (create, read, update, delete)"
        log_info "âœ… Adoption Plans (assign products, create/update/delete plans)"
        log_info "âœ… Import/Export (full data export, custom attributes)"
        log_info "âœ… Telemetry Evaluation (success criteria, multiple data types)"
        echo ""
        return 0
    else
        echo ""
        echo -e "${RED}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        log_error "âŒ COMPREHENSIVE E2E TEST FAILED!"
        echo -e "${RED}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        echo ""
        log_warning "Check the test output above for specific failures"
        log_info "Fix any issues and run './dap test' again"
        return 1
    fi
}

# Run unit/integration tests on shadow database (dap_test)
run_unit_tests() {
    log_header "UNIT & INTEGRATION TESTS (Shadow Database)"
    
    echo ""
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${CYAN}ğŸ§ª DAP Test Runner - Shadow Database Mode${NC}"
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    log_info "ğŸ“ Working Directory: $BACKEND_DIR"
    log_info "ğŸ—ƒï¸  Database: dap_test (shadow copy - dev data protected!)"
    log_info "ğŸ”§ NODE_ENV: test"
    echo ""
    
    # Parse optional arguments
    local pattern=""
    local coverage=false
    
    while [ "$#" -gt 0 ]; do
        case "$1" in
            --pattern=*)
                pattern="${1#*=}"
                log_info "ğŸ” Test Pattern: $pattern"
                ;;
            --coverage)
                coverage=true
                log_info "ğŸ“Š Coverage: enabled"
                ;;
            *)
                pattern="$1"
                log_info "ğŸ” Test Pattern: $pattern"
                ;;
        esac
        shift
    done
    
    echo ""
    
    # Ensure test database exists
    log_info "â³ Ensuring test database exists..."
    
    if use_mac_mode; then
        # Mac: Use local psql (Homebrew PostgreSQL)
        local current_user=$(whoami)
        if ! psql -h localhost -p 5432 -lqt 2>/dev/null | cut -d \| -f 1 | grep -qw 'dap_test'; then
            log_info "ğŸ“ Creating test database..."
            createdb -h localhost -p 5432 dap_test 2>/dev/null || true
        fi
        log_success "âœ… Test database ready"
        
        # Build the command
        local test_cmd="npm test -- --runInBand --passWithNoTests"
        
        if [ "$coverage" = true ]; then
            test_cmd="npm test -- --coverage --runInBand --passWithNoTests"
        fi
        
        if [ -n "$pattern" ]; then
            test_cmd="$test_cmd --testPathPattern=\"$pattern\""
        fi
        
        echo ""
        log_info "ğŸ’» Command (Mac mode):"
        echo "   cd $BACKEND_DIR && DATABASE_URL=postgresql://${current_user}@localhost:5432/dap_test $test_cmd"
        echo ""
        echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
        echo ""
        
        # Run tests with shadow database (Mac)
        cd "$BACKEND_DIR"
        
        export DATABASE_URL="postgresql://${current_user}@localhost:5432/dap_test?schema=public"
        
        # Run migrations on test database
        log_info "ğŸ”„ Running migrations on test database..."
        npx prisma migrate deploy --skip-generate 2>/dev/null || npx prisma db push --skip-generate 2>/dev/null || true
        log_success "âœ… Test database schema ready"
    else
        # Linux: Use Docker
        if ! docker exec $DB_CONTAINER psql -U postgres -c '\l' 2>/dev/null | grep -q 'dap_test'; then
            log_info "ğŸ“ Creating test database..."
            docker exec $DB_CONTAINER psql -U postgres -c "CREATE DATABASE dap_test;" 2>/dev/null || true
        fi
        log_success "âœ… Test database ready"
        
        # Build the command
        local test_cmd="npm test -- --runInBand --passWithNoTests"
        
        if [ "$coverage" = true ]; then
            test_cmd="npm test -- --coverage --runInBand --passWithNoTests"
        fi
        
        if [ -n "$pattern" ]; then
            test_cmd="$test_cmd --testPathPattern=\"$pattern\""
        fi
        
        echo ""
        log_info "ğŸ’» Command (can run from CLI):"
        echo "   cd $BACKEND_DIR && DATABASE_URL=postgres://postgres:postgres@localhost:5432/dap_test $test_cmd"
        echo ""
        echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
        echo ""
        
        # Run tests with shadow database (Linux)
        cd "$BACKEND_DIR"
        
        export DATABASE_URL="postgres://postgres:postgres@localhost:5432/dap_test?schema=public"
    fi
    export NODE_ENV="test"
    export CI="true"
    
    if eval "$test_cmd"; then
        echo ""
        echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        log_success "âœ… Tests PASSED!"
        echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        
        # Show coverage summary if enabled
        if [ "$coverage" = true ] && [ -f "coverage/coverage-summary.json" ]; then
            echo ""
            log_info "ğŸ“Š Coverage Summary:"
            cat coverage/coverage-summary.json | jq -r '.total | "   Lines: \(.lines.pct)% | Statements: \(.statements.pct)% | Functions: \(.functions.pct)% | Branches: \(.branches.pct)%"' 2>/dev/null || true
        fi
        
        return 0
    else
        echo ""
        echo -e "${RED}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        log_error "âŒ Tests FAILED!"
        echo -e "${RED}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        return 1
    fi
}

# Clean restart with database reset
clean_restart() {
    log_header "CLEAN RESTART WITH SAMPLE DATA"
    
    echo -e "${RED}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${RED}â•‘  âš ï¸  DANGER: THIS WILL PERMANENTLY DELETE ALL YOUR DATA!         â•‘${NC}"
    echo -e "${RED}â•‘                                                                   â•‘${NC}"
    echo -e "${RED}â•‘  The following will be DELETED:                                   â•‘${NC}"
    echo -e "${RED}â•‘    â€¢ ALL products (including your custom products)                â•‘${NC}"
    echo -e "${RED}â•‘    â€¢ ALL tasks, outcomes, licenses, releases                      â•‘${NC}"
    echo -e "${RED}â•‘    â€¢ ALL customers and their adoption plans                       â•‘${NC}"
    echo -e "${RED}â•‘    â€¢ ALL solutions and assignments                                â•‘${NC}"
    echo -e "${RED}â•‘                                                                   â•‘${NC}"
    echo -e "${RED}â•‘  Users will be PRESERVED (admin accounts will remain)             â•‘${NC}"
    echo -e "${RED}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    echo "To preserve your data, use './dap add-sample' instead."
    echo ""
    echo -e "${YELLOW}Type 'DELETE' to confirm, or press Ctrl+C to cancel:${NC}"
    read -r confirmation
    
    if [ "$confirmation" != "DELETE" ]; then
        log_info "Operation cancelled. Your data is safe."
        exit 0
    fi
    
    echo ""
    log_warning "â±ï¸  Starting in 5 seconds... Press Ctrl+C to abort!"
    sleep 5
    
    # Use force kill to ensure clean shutdown
    force_kill_all
    manage_docker stop
    
    echo ""
    sleep 3
    
    # Clean database first
    log_info "Setting up clean database..."
    if ! manage_docker start; then
        log_error "Failed to start database"
        exit 1
    fi
    
    # Wait a moment for DB to be ready
    sleep 3
    clean_database
    
    # Start services
    echo ""
    start_backend || exit 1
    start_frontend || exit 1
    
    # Wait for backend to be ready and create adoption plans
    echo ""
    log_info "Creating adoption plans for all customer assignments..."
    sleep 3  # Give backend time to fully initialize
    
    if ! create_adoption_plans; then
        log_warning "âš ï¸  Failed to create adoption plans automatically"
        log_info "You can create them manually by running: ./dap add-sample"
    fi
    
    echo ""
    log_success "Clean restart completed!"
    log_info "âœ… Database: Clean with 5 Cisco products and 62 tasks (comprehensive telemetry)"
    log_info "âœ… Solutions: 2 solution bundles with test data"
    log_info "âœ… Backend API: http://localhost:$BACKEND_PORT/graphql"
    log_info "âœ… Frontend App: http://localhost:$FRONTEND_PORT"
    echo ""
    log_info "ğŸ”„ Press Ctrl+Shift+R in your browser to see the enhanced sample data!"
}

# Add complete networking/security sample data  
add_sample_data() {
    log_header "ADDING COMPLETE SAMPLE DATA (PRODUCTS + SOLUTIONS)"
    log_info "This will add comprehensive sample data including customers, adoption plans, and solution bundles"
    
    # Check if database container is running
    if [ -z "$DB_CONTAINER" ]; then
        log_error "No database container found. Run '$0 start' first."
        exit 1
    fi
    
    if ! docker ps --format "{{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
        log_error "Database container '$DB_CONTAINER' is not running. Run '$0 start' first."
        exit 1
    fi
    
    # Check if complete sample data file exists
    if [ ! -f "$PROJECT_DIR/create-complete-sample-data.sql" ]; then
        log_error "âŒ create-complete-sample-data.sql not found."
        exit 1
    fi
    
    # Execute the complete sample data script
    log_info "ğŸ“ Loading complete networking & security sample data..."
    log_info "   â€¢ 5 Cisco Products (Duo, SD-WAN, Secure Firewall, ISE, Secure Access Sample)"
    log_info "   â€¢ 2 Solutions (Hybrid Private Access, SASE)"
    log_info "   â€¢ 2 Customers (ACME with Hybrid Private Access, Chase with SASE)" 
    log_info "   â€¢ 2 Customer solution assignments"
    log_info "   â€¢ 62+ Tasks with comprehensive telemetry attributes"
    
    if docker exec -i "$DB_CONTAINER" psql -U postgres -d dap < "$PROJECT_DIR/create-complete-sample-data.sql" 2>&1 | tee /tmp/dap_sample.log; then
        echo ""
        log_success "âœ… Complete sample data created successfully!"
        
        # Count what was created
        local products=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Product\" WHERE id LIKE 'prod-%';" 2>/dev/null | tr -d ' ')
        local customers=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Customer\" WHERE id LIKE 'customer-%';" 2>/dev/null | tr -d ' ')
        local customer_solutions=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerSolution\";" 2>/dev/null | tr -d ' ')
        local solutions=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Solution\";" 2>/dev/null | tr -d ' ')
        local tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Task\" WHERE \"productId\" LIKE 'prod-%';" 2>/dev/null | tr -d ' ')
        local telemetry=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"TelemetryAttribute\" WHERE \"taskId\" LIKE 'task-%';" 2>/dev/null | tr -d ' ')
        
        echo ""
        log_info "ğŸ“Š Sample data created:"
        log_info "  ğŸ” $products Cisco Products (Duo, SD-WAN, Secure Firewall, ISE, Secure Access Sample)"
        log_info "  ğŸ“¦ $solutions Solutions (Hybrid Private Access, SASE)"
        log_info "  ğŸ¢ $customers Customers (ACME, Chase)"
        log_info "  ğŸ”— $customer_solutions Customer Solution Assignments"
        log_info "  âš™ï¸  $tasks Product Tasks (10-14 per product with telemetry)"
        log_info "  ğŸ“Š $telemetry Telemetry Attributes with detailed success criteria"
        echo ""
        log_info "âœ… Sample data loaded! Now creating adoption plans..."
        
        # Create adoption plans for all customer assignments (products and solutions)
        # Note: Backend must be started first for adoption plan creation to work
        if check_port $BACKEND_PORT; then
            create_adoption_plans
        else
            log_warning "âš ï¸  Backend not running. Start backend and run './dap add-sample' again to create adoption plans"
            log_info "ğŸ’¡ Or run: cd backend && npm run seed"
        fi
    else
        echo ""
        log_error "âŒ Failed to create complete sample data"
        log_info "Check /tmp/dap_sample.log for error details"
        exit 1
    fi
    
    echo ""
    log_info "ğŸ”„ Refresh your browser (Ctrl+Shift+R) to see the complete sample data!"
    log_success "ğŸ‰ All sample data loaded successfully - Products, Solutions, Customers, and Adoption Plans!"
}

# Seed solution data using backend seed script
seed_solution_data() {
    log_header "SEEDING SOLUTION DATA"
    log_info "ğŸ“¦ Creating solution bundles and test data..."
    
    # Check if backend is accessible
    if ! check_port $BACKEND_PORT; then
        log_warning "âš ï¸  Backend is not running. Starting backend first..."
        start_backend || {
            log_error "âŒ Failed to start backend. Cannot seed solution data."
            return 1
        }
        # Give it a moment to fully initialize
        sleep 5
    fi
    
    # Run the seed script which includes solution seeding
    log_info "ğŸŒ± Running backend seed script with solution data..."
    cd "$BACKEND_DIR"
    
    if npm run seed 2>&1 | tee /tmp/dap_solution_seed.log; then
        echo ""
        log_success "âœ… Solution data seeded successfully!"
        
        # Count what was created
        local solutions=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Solution\";" 2>/dev/null | tr -d ' ')
        local solution_products=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"SolutionProduct\";" 2>/dev/null | tr -d ' ')
        local solution_tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Task\" WHERE \"solutionId\" IS NOT NULL;" 2>/dev/null | tr -d ' ')
        local customer_solutions=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerSolution\";" 2>/dev/null | tr -d ' ')
        
        echo ""
        log_info "ğŸ“Š Solution data created:"
        log_info "  ğŸ“¦ $solutions Solutions (Hybrid Private Access, SASE)"
        log_info "  ğŸ”— $solution_products Product-Solution Links (3 products per solution)"
        log_info "  âš™ï¸  $solution_tasks Solution-specific Tasks"
        log_info "  ğŸ¢ $customer_solutions Customer Solution Assignments"
        echo ""
        log_success "ğŸ‰ Solution adoption system is ready for testing!"
    else
        echo ""
        log_error "âŒ Failed to seed solution data"
        log_info "Check /tmp/dap_solution_seed.log for error details"
        if grep -q "already exists\|duplicate" /tmp/dap_solution_seed.log; then
            log_info "â„¹ï¸  Some solution data may already exist - this is normal"
            return 0
        fi
        return 1
    fi
    
    cd "$PROJECT_DIR"
}

# Create adoption plans for all customer product assignments (ROBUST VERSION)
create_adoption_plans() {
    log_info "ğŸš€ Creating adoption plans for customer product assignments..."
    
    local backend_url="http://localhost:4000/graphql"
    
    # Step 1: Wait for backend to be fully ready with GraphQL health check
    log_info "â³ Waiting for backend GraphQL to be fully ready..."
    local max_wait_attempts=30
    local wait_attempt=1
    
    while [ $wait_attempt -le $max_wait_attempts ]; do
        # Test with a simple GraphQL query to ensure the API is fully functional
        local health_response=$(curl -s -X POST \
            -H "Content-Type: application/json" \
            -H "Authorization: admin" \
            -d '{"query": "query { __typename }"}' \
            "$backend_url" 2>/dev/null)
        
        if echo "$health_response" | jq -e '.data.__typename' >/dev/null 2>&1; then
            log_success "âœ… Backend GraphQL is ready!"
            break
        fi
        
        if [ $wait_attempt -eq $max_wait_attempts ]; then
            log_error "âŒ Backend GraphQL not responding after 60 seconds. Aborting adoption plan creation."
            return 1
        fi
        
        echo -n "."
        sleep 2
        wait_attempt=$((wait_attempt + 1))
    done
    
    # Step 2: Verify prerequisites - customer solutions and telemetry exist
    log_info "ğŸ” Verifying prerequisites..."
    
    local customer_solutions_count=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerSolution\";" 2>/dev/null | tr -d ' ')
    local customer_products_count=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerProduct\";" 2>/dev/null | tr -d ' ')
    local telemetry_count=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"TelemetryAttribute\" WHERE \"taskId\" LIKE 'task-%';" 2>/dev/null | tr -d ' ')
    local task_outcomes_count=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"TaskOutcome\";" 2>/dev/null | tr -d ' ')
    
    log_info "  ğŸ“¦ Customer Solutions: $customer_solutions_count"
    log_info "  ğŸ“‹ Customer Products: $customer_products_count"
    log_info "  ğŸ“Š Telemetry Attributes: $telemetry_count" 
    log_info "  ğŸ¯ Task-Outcome Relationships: $task_outcomes_count"
    
    if [ "$customer_solutions_count" -eq "0" ] && [ "$customer_products_count" -eq "0" ]; then
        log_error "âŒ No customer solutions or products found. Sample data may not have loaded correctly."
        log_info "ğŸ’¡ Check /tmp/dap_sample.log for SQL errors"
        return 1
    fi
    
    if [ "$telemetry_count" -eq "0" ]; then
        log_warning "âš ï¸  No telemetry attributes found. Adding essential telemetry..."
        # Add minimal telemetry to ensure adoption plans work
        docker exec -i "$DB_CONTAINER" psql -U postgres -d dap -c "
            INSERT INTO \"TelemetryAttribute\" (id, \"taskId\", name, description, \"dataType\", \"isRequired\", \"successCriteria\", \"order\", \"isActive\", \"createdAt\", \"updatedAt\") VALUES
            ('tel-sample-1', 'task-fw-001', 'sample_metric', 'Sample telemetry for adoption plans', 'NUMBER', true, '{\"operator\": \">=\", \"value\": 1}', 1, true, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            ON CONFLICT (id) DO NOTHING;
        " >/dev/null 2>&1
    fi
    
    # Step 3: Get actual customer product and solution IDs from database
    log_info "ğŸ“‹ Fetching customer assignments from database..."
    local cp_ids=($(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT id FROM \"CustomerProduct\" ORDER BY id;" 2>/dev/null | tr -d ' ' | grep -v '^$'))
    local cs_ids=($(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT id FROM \"CustomerSolution\" ORDER BY id;" 2>/dev/null | tr -d ' ' | grep -v '^$'))
    
    if [ ${#cp_ids[@]} -eq 0 ] && [ ${#cs_ids[@]} -eq 0 ]; then
        log_error "âŒ No customer product or solution assignments found in database."
        return 1
    fi
    
    if [ ${#cp_ids[@]} -gt 0 ]; then
        log_info "ğŸ“‹ Found ${#cp_ids[@]} customer product assignments: ${cp_ids[*]}"
    fi
    if [ ${#cs_ids[@]} -gt 0 ]; then
        log_info "ğŸ“¦ Found ${#cs_ids[@]} customer solution assignments: ${cs_ids[*]}"
    fi
    
    # Step 4: Create adoption plans with retry logic
    local plans_created=0
    local plans_existed=0
    local solution_plans_created=0
    local solution_plans_existed=0
    
    # Create product adoption plans
    for cp_id in "${cp_ids[@]}"; do
        log_info "   ğŸ”„ Processing product adoption plan for $cp_id..."
        
        local retry_attempts=3
        local retry=1
        local success=false
        
        while [ $retry -le $retry_attempts ] && [ "$success" = false ]; do
            if [ $retry -gt 1 ]; then
                log_info "     ğŸ”„ Retry attempt $retry for $cp_id..."
                sleep 3
            fi
            
            local response=$(curl -s -X POST \
                -H "Content-Type: application/json" \
                -H "Authorization: admin" \
                -d "{\"query\": \"mutation { createAdoptionPlan(customerProductId: \\\"$cp_id\\\") { id totalTasks completedTasks progressPercentage } }\"}" \
                "$backend_url" 2>/dev/null)
            
            # Check for successful creation
            if echo "$response" | jq -e '.data.createAdoptionPlan.id' >/dev/null 2>&1; then
                local adoption_id=$(echo "$response" | jq -r '.data.createAdoptionPlan.id')
                local total_tasks=$(echo "$response" | jq -r '.data.createAdoptionPlan.totalTasks')
                log_success "     âœ… Created product adoption plan $adoption_id with $total_tasks tasks"
                plans_created=$((plans_created + 1))
                success=true
                
            # Check if already exists
            elif echo "$response" | grep -q "already exists\|Adoption plan already exists"; then
                log_info "     â„¹ï¸  Product adoption plan already exists for $cp_id"
                plans_existed=$((plans_existed + 1))
                success=true
                
            # Handle errors
            else
                log_warning "     âš ï¸  Attempt $retry failed for $cp_id"
                if [ $retry -eq $retry_attempts ]; then
                    log_error "     âŒ All retry attempts failed for $cp_id"
                    echo "Response: $response" | head -3
                fi
            fi
            
            retry=$((retry + 1))
        done
    done
    
    # Create solution adoption plans
    for cs_id in "${cs_ids[@]}"; do
        log_info "   ğŸ”„ Processing solution adoption plan for $cs_id..."
        
        local retry_attempts=3
        local retry=1
        local success=false
        
        while [ $retry -le $retry_attempts ] && [ "$success" = false ]; do
            if [ $retry -gt 1 ]; then
                log_info "     ğŸ”„ Retry attempt $retry for $cs_id..."
                sleep 3
            fi
            
            local response=$(curl -s -X POST \
                -H "Content-Type: application/json" \
                -H "Authorization: admin" \
                -d "{\"query\": \"mutation { createSolutionAdoptionPlan(customerSolutionId: \\\"$cs_id\\\") { id totalTasks completedTasks progressPercentage } }\"}" \
                "$backend_url" 2>/dev/null)
            
            # Check for successful creation
            if echo "$response" | jq -e '.data.createSolutionAdoptionPlan.id' >/dev/null 2>&1; then
                local adoption_id=$(echo "$response" | jq -r '.data.createSolutionAdoptionPlan.id')
                local total_tasks=$(echo "$response" | jq -r '.data.createSolutionAdoptionPlan.totalTasks')
                log_success "     âœ… Created solution adoption plan $adoption_id with $total_tasks tasks"
                solution_plans_created=$((solution_plans_created + 1))
                success=true
                
            # Check if already exists
            elif echo "$response" | grep -q "already exists\|Solution adoption plan already exists"; then
                log_info "     â„¹ï¸  Solution adoption plan already exists for $cs_id"
                solution_plans_existed=$((solution_plans_existed + 1))
                success=true
                
            # Handle errors
            else
                log_warning "     âš ï¸  Attempt $retry failed for $cs_id"
                if [ $retry -eq $retry_attempts ]; then
                    log_error "     âŒ All retry attempts failed for $cs_id"
                    echo "Response: $response" | head -3
                fi
            fi
            
            retry=$((retry + 1))
        done
    done
    
    # Step 5: Final verification and summary
    sleep 2
    local final_product_plans=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"AdoptionPlan\";" 2>/dev/null | tr -d ' ')
    local final_solution_plans=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"SolutionAdoptionPlan\";" 2>/dev/null | tr -d ' ')
    local final_tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerTask\";" 2>/dev/null | tr -d ' ')
    local final_solution_tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerSolutionTask\";" 2>/dev/null | tr -d ' ')
    local final_telemetry=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerTelemetryAttribute\";" 2>/dev/null | tr -d ' ')
    
    echo ""
    log_success "ğŸ‰ Adoption Plan Creation Complete!"
    log_info "ğŸ“Š Product Plans:"
    log_info "  ğŸ†• Newly Created: $plans_created"
    log_info "  ğŸ“‹ Already Existed: $plans_existed"
    log_info "  ğŸ“Š Total: $final_product_plans"
    log_info "ğŸ“¦ Solution Plans:"
    log_info "  ğŸ†• Newly Created: $solution_plans_created"
    log_info "  ğŸ“‹ Already Existed: $solution_plans_existed"
    log_info "  ğŸ“Š Total: $final_solution_plans"
    log_info "âš™ï¸  Tasks:"
    log_info "  ğŸ“‹ Customer Product Tasks: $final_tasks"
    log_info "  ğŸ“¦ Customer Solution Tasks: $final_solution_tasks"
    log_info "  ğŸ“ˆ Telemetry Attributes: $final_telemetry"
    
    local total_expected=$((${#cp_ids[@]} + ${#cs_ids[@]}))
    local total_actual=$((final_product_plans + final_solution_plans))
    
    if [ $total_actual -eq $total_expected ]; then
        echo ""
        log_success "âœ… SUCCESS: All $total_actual adoption plans created successfully!"
        log_success "ğŸš€ Complete sample data ready for testing and demonstrations!"
        
        # Show detailed breakdown
        echo ""
        log_info "ğŸ“‹ Customer Adoption Plan Details:"
        docker exec $DB_CONTAINER psql -U postgres -d dap -c "
            SELECT 
                c.name as \"Customer\",
                p.name as \"Product\", 
                ap.\"totalTasks\" as \"Tasks\"
            FROM \"AdoptionPlan\" ap
            JOIN \"CustomerProduct\" cp ON ap.\"customerProductId\" = cp.id
            JOIN \"Customer\" c ON cp.\"customerId\" = c.id
            JOIN \"Product\" p ON cp.\"productId\" = p.id
            ORDER BY c.name, p.name;
        " 2>/dev/null | grep -v "^$"
        
    else
        echo ""
        log_warning "âš ï¸  Only $final_plans out of ${#cp_ids[@]} adoption plans were created."
        log_info "ğŸ’¡ You can create missing plans manually in the frontend or run this command again."
    fi
}

# Remove sample data while preserving user-created data
reset_sample_data() {
    log_info "Removing sample data while preserving user-created data..."
    
    # Check if database container is running
    if [ -z "$DB_CONTAINER" ]; then
        log_error "No database container found. Run '$0 start' first."
        exit 1
    fi
    
    if ! docker ps --format "{{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
        log_error "Database container '$DB_CONTAINER' is not running. Run '$0 start' first."
        exit 1
    fi
    
    # Check if remove-sample-data.sql exists
    if [ ! -f "$PROJECT_DIR/remove-sample-data.sql" ]; then
        log_error "âŒ remove-sample-data.sql not found. This script is required for selective sample data removal."
        exit 1
    fi
    
    # Execute the sample data removal script
    log_info "ğŸ—‘ï¸ Removing sample data (preserving user data)..."
    if docker exec -i "$DB_CONTAINER" psql -U postgres -d dap < "$PROJECT_DIR/remove-sample-data.sql"; then
        echo ""
        log_success "âœ… Sample data removed successfully!"
        
        # Show remaining data
        local products=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Product\" WHERE \"deletedAt\" IS NULL;" 2>/dev/null | tr -d ' ')
        local tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Task\" WHERE \"deletedAt\" IS NULL;" 2>/dev/null | tr -d ' ')
        
        echo ""
        log_info "ğŸ“Š Removed sample products (if they existed):"
        log_info "  â€¢ prod-cisco-duo (Cisco Duo MFA)"
        log_info "  â€¢ prod-cisco-sdwan (Cisco SD-WAN)"
        log_info "  â€¢ prod-cisco-firewall (Cisco Secure Firewall)"
        log_info "  â€¢ prod-cisco-ise (Cisco ISE)"
        log_info "  â€¢ prod-cisco-secure-access-sample (Cisco Secure Access Sample)"
        log_info "  â€¢ prod-sdwan-platform (SD-WAN Platform)"
        log_info "  â€¢ prod-cloud-security (Cloud Security Platform)"
        echo ""
        log_info "ğŸ“Š Removed ALL customer adoption data:"
        log_info "  â€¢ All customer product assignments"
        log_info "  â€¢ All adoption plans"
        log_info "  â€¢ All customer tasks and telemetry"
        log_info "  â€¢ Customer solutions for sample products"
        echo ""
        log_info "ğŸ“Š Remaining database contains:"
        log_info "  ğŸ“¦ $products Products (user-created)"
        log_info "  ğŸ“‹ $tasks Tasks (user-created)"
        log_info "  ğŸ‘¥ Customers (preserved, but unassigned)"
        echo ""
        log_info "âœ… Ready for fresh customer assignments!"
    else
        log_error "âŒ Failed to remove sample data"
        exit 1
    fi
    
    log_info "ğŸ”„ Refresh your browser to see the updated data!"
}

# Show help
show_help() {
    echo -e "${PURPLE}DAP Application Manager${NC}"
    echo ""
    echo "All-in-one script to manage the DAP application lifecycle."
    echo ""
    echo "Usage: $0 [command]"
    echo ""
    echo "Commands:"
    echo -e "  ${GREEN}start${NC}          - Start all application services"
    echo -e "  ${RED}stop${NC}           - Stop all application services" 
    echo -e "  ${YELLOW}restart${NC}        - Restart services (optional: frontend|backend) [preserves data]"
    echo -e "  ${GREEN}sync${NC}           - ğŸš€ RECOMMENDED: Pull + rebuild + migrate + restart (bulletproof)"
    echo -e "  ${CYAN}rebuild${NC}        - âœ… Rebuild components (optional: frontend|backend) [preserves data]"
    echo -e "  ${BLUE}migrate${NC}        - Run database migrations (explicit only)"
    echo -e "  ${PURPLE}full-rebuild${NC}   - âš ï¸  Rebuild all + clean restart (wipes database)"
    echo -e "  ${CYAN}clean-restart${NC}  - âš ï¸  FORCE KILL, WIPES ALL DATA, then loads fresh sample data"
    echo -e "  ${BLUE}add-sample${NC}     - âœ… Add sample data (preserves existing user data)"
    echo -e "  ${PURPLE}reset-sample${NC}   - âœ… Remove sample data only (preserves user data)"
    echo -e "  ${YELLOW}restart-db${NC}     - Restart database container (clears ALL connections)"
    echo -e "  ${BLUE}status${NC}         - Show status of all services and data"
    echo -e "  ${PURPLE}help${NC}           - Show this help message"
    echo ""
    echo "Testing:"
    echo -e "  Use ${CYAN}./dap-test${NC} for all test commands:"
    echo "    ./dap-test e2e        # Run comprehensive E2E tests"
    echo "    ./dap-test unit       # Run unit tests"
    echo "    ./dap-test tags       # Run tags tests"
    echo "    ./dap-test all        # Run all tests"
    echo "    ./dap-test help       # Show all test commands"
    echo ""
    echo "Mode detection:"
    echo "  â€¢ macOS => mac-demo (uses scripts/mac-light-deploy.sh for light prod demo)"
    echo "  â€¢ Linux => linux-dev (full development toolkit)"
    echo "  â€¢ Override with DAP_MODE=mac-demo|linux-dev ./dap <command>"
    echo ""
    echo "Examples:"
    echo "  $0 sync                 # ğŸš€ BEST: Pull latest, rebuild, migrate, restart"
    echo "  $0 start                # Start for daily development"
    echo "  $0 restart frontend     # Restart only frontend"
    echo "  $0 rebuild backend      # Rebuild and restart backend only"
    echo "  $0 migrate              # Run pending database migrations"
    echo "  $0 add-sample           # âœ… Add sample data (preserves your data)"
    echo "  $0 reset-sample         # âœ… Remove sample data (preserves your data)"
    echo "  $0 full-rebuild         # âš ï¸  Rebuild everything + fresh database"
    echo "  $0 clean-restart        # âš ï¸  DANGER: Wipes everything, fresh start"
    echo "  $0 status               # Check what's running"
    echo "  $0 stop                 # End development session"
    echo ""
    echo "Components managed:"
    echo "  â€¢ PostgreSQL Database (Docker container)"
    echo "  â€¢ Backend GraphQL API (Node.js on port $BACKEND_PORT)"
    echo "  â€¢ Frontend React App (Vite on port $FRONTEND_PORT)"
    echo ""
    echo "The clean-restart command provides:"
    echo "  â€¢ 5 comprehensive products with mandatory attributes"
    echo "  â€¢ 2 solution bundles (Security, Digital Transformation)"
    echo "  â€¢ Tasks with howToDoc and howToVideo fields"
    echo "  â€¢ Complete data relationships and constraints"
    echo "  â€¢ Essential licenses, outcomes, and releases for each product"
    echo "  â€¢ Customer solution assignments and adoption tracking"
    echo ""
    echo "Rebuild options:"
    echo "  â€¢ sync: ğŸš€ BULLETPROOF - Git pull + rebuild + migrate + restart (use after being away)"
    echo "  â€¢ rebuild: âœ… RECOMMENDED - Rebuilds frontend & backend, preserves database"
    echo "  â€¢ full-rebuild: âš ï¸  Rebuilds everything + wipes database"
    echo ""
    echo "Sample data management:"
    echo "  â€¢ add-sample: âœ… RECOMMENDED - Adds sample data, preserves your existing data"
    echo "  â€¢ reset-sample: âœ… SAFE - Removes only sample data, keeps your products/customers"
    echo "  â€¢ clean-restart: âš ï¸  DESTRUCTIVE - Wipes EVERYTHING (use only for complete reset)"
    echo ""
    echo "âš ï¸  IMPORTANT: clean-restart deletes ALL data including manually created products!"
    echo "   To preserve your 'Cisco Secure Access' or other custom data, use 'add-sample' instead."
}

# Main script logic
main() {
    # Change to project directory
    cd "$PROJECT_DIR"
    
    case "${1:-}" in
        dev)
            dev_mode
            ;;
        start)
            if use_mac_mode; then
                mac_start
            else
                start_all
            fi
            ;;
        stop)
            if use_mac_mode; then
                mac_stop
            else
                stop_all
            fi
            ;;
        restart)
            shift
            target=${1:-all}
            log_header "RESTARTING $(echo "$target" | tr '[:lower:]' '[:upper:]')"
            
            if use_mac_mode; then
                mac_restart
            elif [ "$target" == "backend" ]; then
                stop_backend
                start_backend
            elif [ "$target" == "frontend" ]; then
                stop_frontend
                start_frontend
            else
                restart_all
            fi
            ;;
        migrate)
            log_header "RUNNING DATABASE MIGRATIONS"
            (cd "$BACKEND_DIR" && npx prisma migrate deploy) || log_error "Migration failed"
            ;;
        sync)
            # BULLETPROOF SYNC: Pull, rebuild, migrate, restart
            log_header "SYNC: PULL + REBUILD + MIGRATE + RESTART"
            log_info "This command pulls latest code, rebuilds everything, and restarts services"
            echo ""
            
            # Step 1: Stop all services first (prevent file locks)
            log_info "ğŸ“› Step 1/6: Stopping all services..."
            force_kill_all 2>/dev/null || true
            sleep 2
            
            # Step 2: Git pull with error handling
            log_info "ğŸ“¥ Step 2/6: Pulling latest code..."
            cd "$PROJECT_DIR"
            
            # Stash any local changes
            if ! git diff --quiet 2>/dev/null; then
                log_warning "Local changes detected, stashing..."
                git stash push -m "dap-sync-$(date +%Y%m%d-%H%M%S)" || true
            fi
            
            # Pull with retry
            local pull_attempts=3
            local pull_success=false
            for attempt in $(seq 1 $pull_attempts); do
                if git pull --rebase origin main 2>&1; then
                    log_success "Git pull successful"
                    pull_success=true
                    break
                else
                    log_warning "Pull attempt $attempt failed, retrying..."
                    sleep 2
                fi
            done
            
            if [ "$pull_success" = false ]; then
                log_error "Git pull failed after $pull_attempts attempts"
                log_info "Try: git fetch origin && git reset --hard origin/main"
                exit 1
            fi
            
            # Step 3: Ensure database is running
            log_info "ğŸ—„ï¸  Step 3/6: Ensuring database is running..."
            if ! manage_docker start; then
                log_error "Failed to start database"
                exit 1
            fi
            sleep 3
            
            # Step 4: Backend rebuild with dependency cleanup
            log_info "ğŸ”¨ Step 4/6: Rebuilding backend..."
            cd "$BACKEND_DIR"
            
            # Clean node_modules if package-lock changed
            if git diff HEAD~1 --name-only 2>/dev/null | grep -q "package-lock.json"; then
                log_info "package-lock.json changed, cleaning node_modules..."
                rm -rf node_modules 2>/dev/null || true
            fi
            
            # Install dependencies with retry
            local npm_attempts=3
            local npm_success=false
            for attempt in $(seq 1 $npm_attempts); do
                if npm install --legacy-peer-deps 2>&1; then
                    npm_success=true
                    break
                else
                    log_warning "npm install attempt $attempt failed, cleaning cache..."
                    npm cache clean --force 2>/dev/null || true
                    rm -rf node_modules 2>/dev/null || true
                    sleep 2
                fi
            done
            
            if [ "$npm_success" = false ]; then
                log_error "Backend npm install failed"
                exit 1
            fi
            
            # Build backend
            if ! npm run build; then
                log_error "Backend build failed"
                exit 1
            fi
            log_success "Backend built"
            
            # Step 5: Database schema sync (THE CRITICAL PART)
            log_info "ğŸ”„ Step 5/6: Syncing database schema..."
            
            # Generate Prisma Client first
            if ! npx prisma generate; then
                log_error "Prisma generate failed"
                exit 1
            fi
            log_success "Prisma Client generated"
            
            # Try migrate deploy first (for production-like migrations)
            log_info "Attempting prisma migrate deploy..."
            if npx prisma migrate deploy 2>&1; then
                log_success "Migrations applied successfully"
            else
                log_warning "migrate deploy had issues, trying db push..."
                # Fallback to db push (handles schema drift)
                if npx prisma db push --accept-data-loss 2>&1; then
                    log_success "Schema pushed successfully (db push)"
                else
                    log_error "Both migrate and db push failed!"
                    log_info "Try manually: cd backend && npx prisma migrate reset"
                    exit 1
                fi
            fi
            
            # Step 6: Frontend rebuild
            log_info "ğŸ¨ Step 6/6: Rebuilding frontend..."
            cd "$FRONTEND_DIR"
            
            # Clean node_modules if package-lock changed
            if git diff HEAD~1 --name-only 2>/dev/null | grep -q "frontend/package-lock.json"; then
                log_info "Frontend package-lock.json changed, cleaning node_modules..."
                rm -rf node_modules 2>/dev/null || true
            fi
            
            if ! npm install 2>&1; then
                log_warning "Frontend npm install failed, cleaning and retrying..."
                rm -rf node_modules 2>/dev/null || true
                npm cache clean --force 2>/dev/null || true
                if ! npm install 2>&1; then
                    log_error "Frontend npm install failed"
                    exit 1
                fi
            fi
            
            # Build frontend (dev mode for dev server)
            if ! npm run build -- --mode development 2>&1; then
                log_warning "Frontend build failed, but continuing (dev server will handle it)"
            fi
            log_success "Frontend ready"
            
            # Start all services
            cd "$PROJECT_DIR"
            echo ""
            log_header "STARTING SERVICES"
            start_services
            
            echo ""
            log_success "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            log_success "âœ… SYNC COMPLETE!"
            log_success "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            log_info "Backend API: http://localhost:$BACKEND_PORT/graphql"
            log_info "Frontend App: http://localhost:$FRONTEND_PORT"
            echo ""
            ;;
        rebuild)
            shift
            target=${1:-all}
            log_header "REBUILDING $(echo "$target" | tr '[:lower:]' '[:upper:]')"
            log_info "This will rebuild components without affecting database data"
            log_info "ğŸ’¡ TIP: Use './dap sync' for pull + rebuild + migrate"
            echo ""
            
            # Rebuild Backend
            if [ "$target" == "backend" ] || [ "$target" == "all" ]; then
                log_info "Stopping backend..."
                stop_backend
                
                log_info "ğŸ”¨ Rebuilding Backend..."
                cd "$BACKEND_DIR"
                if npm install --legacy-peer-deps && npm run build; then
                    log_success "Backend built successfully"
                    
                    log_info "ğŸ”„ Updating Database Schema (Prisma)..."
                    # Generate Prisma Client
                    if npx prisma generate; then
                        log_success "Prisma Client generated"
                    else
                        log_error "Failed to generate Prisma Client"
                        exit 1
                    fi
                    
                    # Push schema to DB (handles schema changes)
                    if npx prisma db push; then
                        log_success "Database schema synced"
                    else
                        log_error "Failed to push database schema"
                        exit 1
                    fi
                else
                    log_error "Failed to build backend"
                    exit 1
                fi
            fi
            
            # Rebuild Frontend
            if [ "$target" == "frontend" ] || [ "$target" == "all" ]; then
                log_info "Stopping frontend..."
                stop_frontend
                
                log_info "ğŸ”¨ Rebuilding Frontend..."
                cd "$FRONTEND_DIR"
                if npm install && npm run build -- --mode development; then
                    log_success "Frontend built successfully"
                else
                    log_error "Failed to build frontend"
                    exit 1
                fi
            fi
            
            cd "$PROJECT_DIR"
            log_success "âœ… Rebuild complete!"
            echo ""
            
            # Restart services
            if [ "$target" == "backend" ]; then
                start_backend
            elif [ "$target" == "frontend" ]; then
                start_frontend
            else
                start_services
            fi
            ;;
        restart-devtools)
            restart_devtools
            ;;
        full-rebuild)
            log_header "FULL REBUILD WITH CLEAN DATABASE"
            echo -e "${RED}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
            echo -e "${RED}â•‘  âš ï¸  WARNING: This will REBUILD + WIPE DATABASE!           â•‘${NC}"
            echo -e "${RED}â•‘  All products, tasks, customers will be DELETED!           â•‘${NC}"
            echo -e "${RED}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
            echo ""
            echo -e "${YELLOW}Type 'REBUILD' to confirm, or press Ctrl+C to cancel:${NC}"
            read -r confirmation
            
            if [ "$confirmation" != "REBUILD" ]; then
                log_info "Operation cancelled. Use './dap rebuild' for safe rebuild."
                exit 0
            fi
            
            log_info "ğŸ”¨ Rebuilding Backend..."
            cd "$BACKEND_DIR"
            npm install --legacy-peer-deps
            npm run build
            
            log_info "ğŸ”¨ Rebuilding Frontend..."
            cd "$FRONTEND_DIR"
            npm install
            npm run build
            
            cd "$PROJECT_DIR"
            log_info "ğŸ—‘ï¸  Performing clean restart with fresh database..."
            clean_restart
            ;;
        add-sample)
            add_sample_data
            ;;
        reset-sample)
            reset_sample_data
            ;;
        test|unit-test|e2e|tags|integration)
            log_warning "Testing commands have moved to ./dap-test"
            echo ""
            log_info "Use one of the following:"
            echo "  ./dap-test e2e         # Run comprehensive E2E tests"
            echo "  ./dap-test unit        # Run unit tests"
            echo "  ./dap-test tags        # Run tags tests"
            echo "  ./dap-test integration # Run integration tests"
            echo "  ./dap-test all         # Run all tests"
            echo "  ./dap-test help        # Show all test options"
            echo ""
            # If dap-test exists and is executable, offer to run it
            if [ -x "$PROJECT_DIR/dap-test" ]; then
                log_info "Running: ./dap-test ${1:-e2e} ${@:2}"
                exec "$PROJECT_DIR/dap-test" "${1:-e2e}" "${@:2}"
            fi
            ;;
        restart-db)
            log_header "RESTARTING DATABASE"
            log_info "This will clear ALL active database connections"
            manage_docker restart
            log_success "Database restarted - all connections cleared"
            ;;
        reset)
            if use_mac_mode; then
                mac_reset
            else
                log_info "For linux-dev mode, use './dap reset-sample' to reset database with sample data"
            fi
            ;;
        status)
            if use_mac_mode; then
                mac_status
            else
                show_status
            fi
            ;;
        help|--help|-h)
            show_help
            ;;
        *)
            if [ -n "${1:-}" ]; then
                log_error "Unknown command: $1"
                echo ""
            fi
            show_help
            ;;
    esac
}

# Check if script is run with sudo (not recommended)
if [ "$EUID" -eq 0 ]; then
    log_warning "Running as root is not recommended. Consider running as a regular user."
fi

# Run main function with all arguments
main "$@"