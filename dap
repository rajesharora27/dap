#!/bin/bash

#######################################################################################
# DAP Application Manager - All-in-One Script
# 
# Manages the complete DAP (Database Application Platform) lifecycle:
# - Application start/stop/restart/status
# - Database cleanup and sample data setup  
# - Browser cache clearing guidance
# - Development environment management
#
# Usage: ./dap [command]
# Commands: start, stop, restart, status, reset, clean-restart, test, add-sample, reset-sample, help
#######################################################################################

set -e

# Configuration - Load from environment or use defaults
APP_NAME="DAP Application"
DB_CONTAINER="$(docker ps -a --format '{{.Names}}' | grep -E '^dap[-_]db[-_]1$|^dap_db_1$|^dap-db-1$|^db$' | head -n 1)"
BACKEND_PORT="${BACKEND_PORT:-4000}"
FRONTEND_PORT="${FRONTEND_PORT:-5173}"
# Use the directory of this script as the project root
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$SCRIPT_DIR"
BACKEND_DIR="$PROJECT_DIR/backend"
FRONTEND_DIR="$PROJECT_DIR/frontend"

# Dependency checks (Docker, Node.js, npm, lsof, pkill)
for dep in docker node npm lsof pkill; do
    if ! command -v $dep >/dev/null 2>&1; then
        echo "[ERROR] Required dependency '$dep' is not installed or not in PATH. Please install it before running this script."
        exit 1
    fi
done

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Logging functions
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_header() { echo -e "${PURPLE}=== $1 ===${NC}"; }

# Check if a port is in use
check_port() {
    local port=$1
    lsof -Pi :$port -sTCP:LISTEN -t >/dev/null 2>&1
}

# Kill processes on a specific port
kill_port() {
    local port=$1
    local service_name=$2
    
    if check_port $port; then
        log_info "Stopping $service_name on port $port..."
        local pids=$(lsof -Pi :$port -sTCP:LISTEN -t 2>/dev/null || true)
        if [ ! -z "$pids" ]; then
            echo "$pids" | xargs kill -TERM 2>/dev/null || true
            sleep 2
            local remaining_pids=$(lsof -Pi :$port -sTCP:LISTEN -t 2>/dev/null || true)
            if [ ! -z "$remaining_pids" ]; then
                echo "$remaining_pids" | xargs kill -KILL 2>/dev/null || true
            fi
            log_success "$service_name stopped"
        fi
    else
        log_info "$service_name not running on port $port"
    fi
}

# Kill Node.js processes related to the project
kill_node_processes() {
    log_info "Stopping all Node.js processes related to the project..."
    pkill -f "ts-node-dev.*src/server.ts" 2>/dev/null || true
    pkill -f "vite.*--port.*5173" 2>/dev/null || true
    pkill -f "npm.*exec.*ts-node-dev" 2>/dev/null || true
    pkill -f "npm.*exec.*vite" 2>/dev/null || true
    sleep 2
    kill_port $BACKEND_PORT "Backend API"
    kill_port $FRONTEND_PORT "Frontend Dev Server"
    log_success "Node.js processes stopped"
}

# Manage Docker containers
manage_docker() {
    local action=$1
    
    case $action in
        start)
            log_info "Starting PostgreSQL database container..."
            if docker ps -a --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                if docker ps --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                    log_info "Database container already running"
                else
                    docker start $DB_CONTAINER
                    log_success "Database container started"
                fi
            else
                log_warning "Database container $DB_CONTAINER not found. Attempting to create it with 'docker compose up -d db'..."
                (cd "$PROJECT_DIR" && docker compose up -d db)
                # Wait for container to appear
                local max_attempts=10
                local attempt=1
                while [ $attempt -le $max_attempts ]; do
                    if docker ps -a --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                        log_success "Database container $DB_CONTAINER created"
                        break
                    fi
                    sleep 1
                    ((attempt++))
                done
                if ! docker ps -a --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                    log_error "Failed to create database container $DB_CONTAINER. Please check your docker-compose.yml."
                    return 1
                fi
            fi
            
            log_info "Waiting for database to be ready..."
            local max_attempts=30
            local attempt=1
            
            while [ $attempt -le $max_attempts ]; do
                if docker exec $DB_CONTAINER pg_isready -U postgres >/dev/null 2>&1; then
                    log_success "Database is ready"
                    break
                fi
                
                if [ $attempt -eq $max_attempts ]; then
                    log_error "Database failed to become ready within 30 seconds"
                    return 1
                fi
                
                echo -n "."
                sleep 1
                ((attempt++))
            done
            ;;
            
        stop)
            log_info "Stopping PostgreSQL database container..."
            if docker ps --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                docker stop $DB_CONTAINER
                log_success "Database container stopped"
            else
                log_info "Database container not running"
            fi
            ;;
            
        status)
            if docker ps --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                log_success "Database container is running"
                docker exec $DB_CONTAINER pg_isready -U postgres >/dev/null 2>&1 && log_success "Database is accepting connections"
            elif docker ps -a --format "table {{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
                log_warning "Database container exists but is not running"
            else
                log_error "Database container not found"
            fi
            ;;
    esac
}

# Start backend
start_backend() {
    log_info "Starting Backend GraphQL API..."
    
    if check_port $BACKEND_PORT; then
        log_warning "Backend already running on port $BACKEND_PORT"
        return 0
    fi
    
    cd "$BACKEND_DIR"
    
    if [ ! -d "node_modules" ]; then
        log_info "Installing backend dependencies..."
        npm install
    fi
    
    log_info "Starting backend server on port $BACKEND_PORT..."
    nohup npm run dev > ../backend.log 2>&1 &
    local backend_pid=$!
    
    local max_attempts=20
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        if check_port $BACKEND_PORT; then
            log_success "Backend API started successfully (PID: $backend_pid)"
            return 0
        fi
        
        if [ $attempt -eq $max_attempts ]; then
            log_error "Backend failed to start within 20 seconds"
            return 1
        fi
        
        echo -n "."
        sleep 1
        ((attempt++))
    done
}

# Start frontend
start_frontend() {
    log_info "Starting Frontend React App..."
    
    if check_port $FRONTEND_PORT; then
        log_warning "Frontend already running on port $FRONTEND_PORT"
        return 0
    fi
    
    cd "$FRONTEND_DIR"
    
    if [ ! -d "node_modules" ]; then
        log_info "Installing frontend dependencies..."
        npm install
    fi
    
    log_info "Starting frontend dev server on port $FRONTEND_PORT..."
    nohup npm run dev > ../frontend.log 2>&1 &
    local frontend_pid=$!
    
    local max_attempts=30
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        if check_port $FRONTEND_PORT; then
            log_success "Frontend dev server started successfully (PID: $frontend_pid)"
            log_success "Frontend available at: http://localhost:$FRONTEND_PORT"
            return 0
        fi
        
        if [ $attempt -eq $max_attempts ]; then
            log_error "Frontend failed to start within 30 seconds"
            return 1
        fi
        
        echo -n "."
        sleep 1
        ((attempt++))
    done
}

# Show application status
show_status() {
    log_header "APPLICATION STATUS"
    
    echo -e "${CYAN}Database (PostgreSQL):${NC}"
    manage_docker status
    
    echo -e "\n${CYAN}Backend API (GraphQL):${NC}"
    if check_port $BACKEND_PORT; then
        log_success "Backend running on port $BACKEND_PORT"
        log_info "API endpoint: http://localhost:$BACKEND_PORT/graphql"
    else
        log_error "Backend not running on port $BACKEND_PORT"
    fi
    
    echo -e "\n${CYAN}Frontend (React/Vite):${NC}"
    if check_port $FRONTEND_PORT; then
        log_success "Frontend running on port $FRONTEND_PORT"
        log_info "Web interface: http://localhost:$FRONTEND_PORT"
    else
        log_error "Frontend not running on port $FRONTEND_PORT"
    fi
    
    echo -e "\n${CYAN}Quick Database Check:${NC}"
    if check_port $BACKEND_PORT && docker exec $DB_CONTAINER pg_isready -U postgres >/dev/null 2>&1; then
        local product_count=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Product\";" 2>/dev/null | tr -d ' ')
        local task_count=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Task\";" 2>/dev/null | tr -d ' ')
        log_info "Database contains: $product_count products, $task_count tasks"
    else
        log_warning "Cannot check database content (database not accessible)"
    fi
}

# Clean database and add sample data
clean_database() {
    log_header "CLEAN DATABASE SETUP"
    log_warning "‚ö†Ô∏è  This will DELETE ALL existing data including user-created products!"
    log_warning "‚ö†Ô∏è  All products, solutions, customers, and relationships will be removed!"
    echo ""
    
    log_info "Cleaning database..."
    
    # Clean all tables
    # Ensure the database container is running
    if ! docker ps --format '{{.Names}}' | grep -q "^$DB_CONTAINER$"; then
        log_error "Database container $DB_CONTAINER is not running. Please start it with 'docker compose up -d db'."
        return 1
    fi

    # Wait for database to be healthy
    local max_attempts=30
    local attempt=1
    while [ $attempt -le $max_attempts ]; do
        if docker exec $DB_CONTAINER pg_isready -U postgres >/dev/null 2>&1; then
            break
        fi
        sleep 1
        ((attempt++))
    done
    if ! docker exec $DB_CONTAINER pg_isready -U postgres >/dev/null 2>&1; then
        log_error "Database is not ready after waiting. Please check the container logs."
        return 1
    fi

    # Clean tables (in proper order to handle foreign key constraints)
    # Based on actual Prisma schema models - deleting from most dependent to least
    docker exec $DB_CONTAINER psql -U postgres -d dap -c "
      -- Level 1: Deepest dependencies (telemetry values, task relationships)
      DELETE FROM \"CustomerTelemetryValue\";
      DELETE FROM \"TelemetryValue\";
      DELETE FROM \"CustomerTaskOutcome\";
      DELETE FROM \"CustomerTaskRelease\";
      
      -- Level 2: Customer adoption tasks and telemetry attributes
      DELETE FROM \"CustomerTelemetryAttribute\";
      DELETE FROM \"CustomerSolutionTask\";
      DELETE FROM \"CustomerTask\";
      DELETE FROM \"TelemetryAttribute\";
      
      -- Level 3: Solution and product adoption plans
      DELETE FROM \"SolutionAdoptionProduct\";
      DELETE FROM \"SolutionAdoptionPlan\";
      DELETE FROM \"AdoptionPlan\";
      
      -- Level 4: Customer assignments (solutions and products)
      DELETE FROM \"CustomerSolution\";
      DELETE FROM \"CustomerProduct\";
      
      -- Level 5: Junction tables (must be before parent tables)
      DELETE FROM \"SolutionProduct\";
      DELETE FROM \"SolutionTaskOrder\";
      DELETE FROM \"TaskOutcome\";
      DELETE FROM \"TaskRelease\";
      
      -- Level 6: Core entities (tasks, outcomes, licenses, releases)
      DELETE FROM \"Task\";
      DELETE FROM \"Outcome\";
      DELETE FROM \"License\";
      DELETE FROM \"Release\";
      DELETE FROM \"CustomAttribute\";
      DELETE FROM \"Telemetry\";
      
      -- Level 7: Top-level entities (products, solutions, customers)
      DELETE FROM \"Product\";
      DELETE FROM \"Solution\";
      DELETE FROM \"Customer\";
      
      -- Level 8: Audit, change tracking, and system tables
      DELETE FROM \"ChangeItem\";
      DELETE FROM \"ChangeSet\";
      DELETE FROM \"AuditLog\";
      DELETE FROM \"LockedEntity\";
      DELETE FROM \"Session\";
      
      -- Note: User table intentionally NOT deleted to preserve admin accounts
    " 2>&1 | tee /tmp/dap_db_cleanup.log
    if grep -qE 'ERROR|FATAL' /tmp/dap_db_cleanup.log; then
        log_error "Failed to clean database tables. See /tmp/dap_db_cleanup.log for details."
        cat /tmp/dap_db_cleanup.log
        return 1
    fi
    log_success "Database cleaned"

    log_info "Creating 5 Cisco products with full attributes..."
    log_info "Loading enhanced Cisco sample data from SQL file..."
    
    # Execute the comprehensive sample data SQL file (showing errors for debugging)
    if ! docker exec -i $DB_CONTAINER psql -U postgres -d dap < "$PROJECT_DIR/create-complete-sample-data.sql" 2>&1 | tee /tmp/dap_sample_load.log; then
        log_error "Failed to create complete sample data."
        log_error "Check /tmp/dap_sample_load.log for details"
        cat /tmp/dap_sample_load.log
        return 1
    fi
    
    # Check for SQL errors
    if grep -qE 'ERROR|FATAL' /tmp/dap_sample_load.log; then
        log_error "SQL errors detected during sample data creation"
        grep -E 'ERROR|FATAL' /tmp/dap_sample_load.log
        return 1
    fi
    
    log_success "Complete sample data created successfully!"

    # Verify what was created
    local products=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Product\";" 2>/dev/null | tr -d ' ')
    local tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Task\";" 2>/dev/null | tr -d ' ')
    local licenses=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"License\";" 2>/dev/null | tr -d ' ')
    local outcomes=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Outcome\";" 2>/dev/null | tr -d ' ')
    local solutions=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Solution\";" 2>/dev/null | tr -d ' ')
    local customers=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Customer\";" 2>/dev/null | tr -d ' ')
    
    log_info "Created comprehensive Cisco sample data:"
    log_info "  üì¶ $products Products (Duo, SD-WAN, Secure Firewall, ISE, Secure Access Sample)"
    log_info "  üìã $tasks Tasks (10-15 tasks per product with full attributes)"
    log_info "  üè∑Ô∏è $licenses Licenses (Essential, Advantage, Signature/Premier/Beyond tiers)"
    log_info "  üéØ $outcomes Outcomes (Security, performance, and compliance metrics)"
    log_info "  üéØ $solutions Solutions (Hybrid Private Access, SASE)"
    log_info "  üè¢ $customers Customers (ACME and Chase)"
    
    # Note: Solutions are already created in the SQL file above
    # No need to run npm run seed here as it would duplicate data
}

# Start all services
start_all() {
    log_header "STARTING $APP_NAME"
    
    manage_docker start || exit 1
    start_backend || exit 1
    start_frontend || exit 1
    
    echo ""
    log_success "All services started successfully!"
    log_info "Database: PostgreSQL running in container"
    log_info "Backend API: http://localhost:$BACKEND_PORT/graphql"
    log_info "Frontend App: http://localhost:$FRONTEND_PORT"
}

# Stop all services
stop_all() {
    log_header "STOPPING $APP_NAME"
    
    kill_node_processes
    manage_docker stop
    docker stop $(docker ps -q --filter "name=dap_") 2>/dev/null || true
    
    log_success "All services stopped"
}

# Restart all services
restart_all() {
    log_header "RESTARTING $APP_NAME"
    
    stop_all
    echo ""
    sleep 2
    start_all
    
    echo ""
    log_header "BROWSER CACHE CLEARING"
    log_warning "If GUI still shows old data, clear your browser cache:"
    log_info "1. Press Ctrl+Shift+R (hard refresh)"
    log_info "2. Or open Private/Incognito window: Ctrl+Shift+N"
    log_info "3. Visit: http://localhost:$FRONTEND_PORT"
}

# Helper function to check if backend is running
check_backend_running() {
    lsof -ti:$BACKEND_PORT >/dev/null 2>&1
}

# Helper function to check if frontend is running
check_frontend_running() {
    lsof -ti:$FRONTEND_PORT >/dev/null 2>&1
}

# Run comprehensive user test
run_comprehensive_test() {
    log_header "COMPREHENSIVE USER TEST"
    
    # Check if comprehensive test script exists
    if [ ! -f "$PROJECT_DIR/comprehensive-user-test.js" ]; then
        log_error "Comprehensive test script not found at $PROJECT_DIR/comprehensive-user-test.js"
        echo ""
        log_info "Please ensure the comprehensive-user-test.js file exists in the project directory."
        return 1
    fi
    
    # Check if Node.js is available
    if ! command -v node >/dev/null 2>&1; then
        log_error "Node.js is not installed or not in PATH. Please install Node.js to run the comprehensive test."
        return 1
    fi
    
    # Check if the application is running
    log_info "Checking application status..."
    if ! check_backend_running && ! check_frontend_running; then
        log_warning "Application is not running. Starting it now..."
        if ! start_all; then
            log_error "Failed to start application. Cannot run comprehensive test."
            return 1
        fi
        echo ""
        log_info "Waiting for services to be fully ready..."
        sleep 5
    fi
    
    # Verify backend is responding
    log_info "Verifying backend API is responding..."
    local max_attempts=10
    local attempt=1
    while [ $attempt -le $max_attempts ]; do
        if curl -s "http://localhost:$BACKEND_PORT/graphql" -H "Content-Type: application/json" -d '{"query":"query{__typename}"}' >/dev/null 2>&1; then
            log_success "Backend API is responding"
            break
        fi
        
        if [ $attempt -eq $max_attempts ]; then
            log_error "Backend API is not responding after $max_attempts attempts"
            return 1
        fi
        
        echo -n "."
        sleep 2
        ((attempt++))
    done
    
    echo ""
    log_info "Running comprehensive end-user test..."
    log_info "This will test complete functionality: Frontend ‚Üí Backend ‚Üí Database"
    echo ""
    
    # Change to project directory and run the test
    cd "$PROJECT_DIR"
    
    # Run the comprehensive test and capture its exit code
    if node comprehensive-user-test.js; then
        echo ""
        log_success "üéâ COMPREHENSIVE TEST PASSED! üéâ"
        log_info "All application functionality is working correctly"
        log_info "‚úÖ Product creation and editing with mandatory attributes"
        log_info "‚úÖ Task management with all attributes (howToDoc, howToVideo)"
        log_info "‚úÖ Database persistence and relationship integrity"
        log_info "‚úÖ Complete end-user workflow validation"
        echo ""
        log_info "The application is ready for production use!"
        return 0
    else
        echo ""
        log_error "‚ùå COMPREHENSIVE TEST FAILED!"
        log_warning "Some functionality may not be working correctly"
        log_info "Check the test output above for specific errors"
        log_info "Fix any issues and run './dap test' again"
        echo ""
        log_info "For help debugging, check:"
        log_info "‚Ä¢ Backend logs: Check terminal where backend is running"
        log_info "‚Ä¢ Frontend logs: Check browser console at http://localhost:$FRONTEND_PORT"
        log_info "‚Ä¢ Database: Ensure PostgreSQL container is running"
        return 1
    fi
}

# Clean restart with database reset
clean_restart() {
    log_header "CLEAN RESTART WITH SAMPLE DATA"
    
    log_warning "‚ö†Ô∏è  WARNING: This will DELETE ALL DATA including user-created products!"
    log_warning "‚ö†Ô∏è  To preserve user data, use './dap add-sample' instead"
    echo ""
    echo "This command is for complete database reset only."
    echo "Press Ctrl+C now to cancel, or wait 5 seconds to continue..."
    sleep 5
    
    stop_all
    echo ""
    sleep 2
    
    # Clean database first
    log_info "Setting up clean database..."
    if ! manage_docker start; then
        log_error "Failed to start database"
        exit 1
    fi
    
    # Wait a moment for DB to be ready
    sleep 3
    clean_database
    
    # Start services
    echo ""
    start_backend || exit 1
    start_frontend || exit 1
    
    # Wait for backend to be ready and create adoption plans
    echo ""
    log_info "Creating adoption plans for all customer assignments..."
    sleep 3  # Give backend time to fully initialize
    
    if ! create_adoption_plans; then
        log_warning "‚ö†Ô∏è  Failed to create adoption plans automatically"
        log_info "You can create them manually by running: ./dap add-sample"
    fi
    
    echo ""
    log_success "Clean restart completed!"
    log_info "‚úÖ Database: Clean with 5 Cisco products and 62 tasks (comprehensive telemetry)"
    log_info "‚úÖ Solutions: 2 solution bundles with test data"
    log_info "‚úÖ Backend API: http://localhost:$BACKEND_PORT/graphql"
    log_info "‚úÖ Frontend App: http://localhost:$FRONTEND_PORT"
    echo ""
    log_info "üîÑ Press Ctrl+Shift+R in your browser to see the enhanced sample data!"
}

# Add complete networking/security sample data  
add_sample_data() {
    log_header "ADDING COMPLETE SAMPLE DATA (PRODUCTS + SOLUTIONS)"
    log_info "This will add comprehensive sample data including customers, adoption plans, and solution bundles"
    
    # Check if database container is running
    if [ -z "$DB_CONTAINER" ]; then
        log_error "No database container found. Run '$0 start' first."
        exit 1
    fi
    
    if ! docker ps --format "{{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
        log_error "Database container '$DB_CONTAINER' is not running. Run '$0 start' first."
        exit 1
    fi
    
    # Check if complete sample data file exists
    if [ ! -f "$PROJECT_DIR/create-complete-sample-data.sql" ]; then
        log_error "‚ùå create-complete-sample-data.sql not found."
        exit 1
    fi
    
    # Execute the complete sample data script
    log_info "üìù Loading complete networking & security sample data..."
    log_info "   ‚Ä¢ 5 Cisco Products (Duo, SD-WAN, Secure Firewall, ISE, Secure Access Sample)"
    log_info "   ‚Ä¢ 2 Solutions (Hybrid Private Access, SASE)"
    log_info "   ‚Ä¢ 2 Customers (ACME with Hybrid Private Access, Chase with SASE)" 
    log_info "   ‚Ä¢ 2 Customer solution assignments"
    log_info "   ‚Ä¢ 62+ Tasks with comprehensive telemetry attributes"
    
    if docker exec -i "$DB_CONTAINER" psql -U postgres -d dap < "$PROJECT_DIR/create-complete-sample-data.sql" 2>&1 | tee /tmp/dap_sample.log; then
        echo ""
        log_success "‚úÖ Complete sample data created successfully!"
        
        # Count what was created
        local products=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Product\" WHERE id LIKE 'prod-%';" 2>/dev/null | tr -d ' ')
        local customers=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Customer\" WHERE id LIKE 'customer-%';" 2>/dev/null | tr -d ' ')
        local customer_solutions=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerSolution\";" 2>/dev/null | tr -d ' ')
        local solutions=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Solution\";" 2>/dev/null | tr -d ' ')
        local tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Task\" WHERE \"productId\" LIKE 'prod-%';" 2>/dev/null | tr -d ' ')
        local telemetry=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"TelemetryAttribute\" WHERE \"taskId\" LIKE 'task-%';" 2>/dev/null | tr -d ' ')
        
        echo ""
        log_info "üìä Sample data created:"
        log_info "  üîê $products Cisco Products (Duo, SD-WAN, Secure Firewall, ISE, Secure Access Sample)"
        log_info "  üì¶ $solutions Solutions (Hybrid Private Access, SASE)"
        log_info "  üè¢ $customers Customers (ACME, Chase)"
        log_info "  üîó $customer_solutions Customer Solution Assignments"
        log_info "  ‚öôÔ∏è  $tasks Product Tasks (10-14 per product with telemetry)"
        log_info "  üìä $telemetry Telemetry Attributes with detailed success criteria"
        echo ""
        log_info "‚úÖ Sample data loaded! Now creating adoption plans..."
        
        # Create adoption plans for all customer assignments (products and solutions)
        # Note: Backend must be started first for adoption plan creation to work
        if check_port $BACKEND_PORT; then
            create_adoption_plans
        else
            log_warning "‚ö†Ô∏è  Backend not running. Start backend and run './dap add-sample' again to create adoption plans"
            log_info "üí° Or run: cd backend && npm run seed"
        fi
    else
        echo ""
        log_error "‚ùå Failed to create complete sample data"
        log_info "Check /tmp/dap_sample.log for error details"
        exit 1
    fi
    
    echo ""
    log_info "üîÑ Refresh your browser (Ctrl+Shift+R) to see the complete sample data!"
    log_success "üéâ All sample data loaded successfully - Products, Solutions, Customers, and Adoption Plans!"
}

# Seed solution data using backend seed script
seed_solution_data() {
    log_header "SEEDING SOLUTION DATA"
    log_info "üì¶ Creating solution bundles and test data..."
    
    # Check if backend is accessible
    if ! check_port $BACKEND_PORT; then
        log_warning "‚ö†Ô∏è  Backend is not running. Starting backend first..."
        start_backend || {
            log_error "‚ùå Failed to start backend. Cannot seed solution data."
            return 1
        }
        # Give it a moment to fully initialize
        sleep 5
    fi
    
    # Run the seed script which includes solution seeding
    log_info "üå± Running backend seed script with solution data..."
    cd "$BACKEND_DIR"
    
    if npm run seed 2>&1 | tee /tmp/dap_solution_seed.log; then
        echo ""
        log_success "‚úÖ Solution data seeded successfully!"
        
        # Count what was created
        local solutions=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Solution\";" 2>/dev/null | tr -d ' ')
        local solution_products=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"SolutionProduct\";" 2>/dev/null | tr -d ' ')
        local solution_tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Task\" WHERE \"solutionId\" IS NOT NULL;" 2>/dev/null | tr -d ' ')
        local customer_solutions=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerSolution\";" 2>/dev/null | tr -d ' ')
        
        echo ""
        log_info "üìä Solution data created:"
        log_info "  üì¶ $solutions Solutions (Hybrid Private Access, SASE)"
        log_info "  üîó $solution_products Product-Solution Links (3 products per solution)"
        log_info "  ‚öôÔ∏è  $solution_tasks Solution-specific Tasks"
        log_info "  üè¢ $customer_solutions Customer Solution Assignments"
        echo ""
        log_success "üéâ Solution adoption system is ready for testing!"
    else
        echo ""
        log_error "‚ùå Failed to seed solution data"
        log_info "Check /tmp/dap_solution_seed.log for error details"
        if grep -q "already exists\|duplicate" /tmp/dap_solution_seed.log; then
            log_info "‚ÑπÔ∏è  Some solution data may already exist - this is normal"
            return 0
        fi
        return 1
    fi
    
    cd "$PROJECT_DIR"
}

# Create adoption plans for all customer product assignments (ROBUST VERSION)
create_adoption_plans() {
    log_info "üöÄ Creating adoption plans for customer product assignments..."
    
    local backend_url="http://localhost:4000/graphql"
    
    # Step 1: Wait for backend to be fully ready with GraphQL health check
    log_info "‚è≥ Waiting for backend GraphQL to be fully ready..."
    local max_wait_attempts=30
    local wait_attempt=1
    
    while [ $wait_attempt -le $max_wait_attempts ]; do
        # Test with a simple GraphQL query to ensure the API is fully functional
        local health_response=$(curl -s -X POST \
            -H "Content-Type: application/json" \
            -H "Authorization: admin" \
            -d '{"query": "query { __typename }"}' \
            "$backend_url" 2>/dev/null)
        
        if echo "$health_response" | jq -e '.data.__typename' >/dev/null 2>&1; then
            log_success "‚úÖ Backend GraphQL is ready!"
            break
        fi
        
        if [ $wait_attempt -eq $max_wait_attempts ]; then
            log_error "‚ùå Backend GraphQL not responding after 60 seconds. Aborting adoption plan creation."
            return 1
        fi
        
        echo -n "."
        sleep 2
        wait_attempt=$((wait_attempt + 1))
    done
    
    # Step 2: Verify prerequisites - customer solutions and telemetry exist
    log_info "üîç Verifying prerequisites..."
    
    local customer_solutions_count=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerSolution\";" 2>/dev/null | tr -d ' ')
    local customer_products_count=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerProduct\";" 2>/dev/null | tr -d ' ')
    local telemetry_count=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"TelemetryAttribute\" WHERE \"taskId\" LIKE 'task-%';" 2>/dev/null | tr -d ' ')
    local task_outcomes_count=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"TaskOutcome\";" 2>/dev/null | tr -d ' ')
    
    log_info "  üì¶ Customer Solutions: $customer_solutions_count"
    log_info "  üìã Customer Products: $customer_products_count"
    log_info "  üìä Telemetry Attributes: $telemetry_count" 
    log_info "  üéØ Task-Outcome Relationships: $task_outcomes_count"
    
    if [ "$customer_solutions_count" -eq "0" ] && [ "$customer_products_count" -eq "0" ]; then
        log_error "‚ùå No customer solutions or products found. Sample data may not have loaded correctly."
        log_info "üí° Check /tmp/dap_sample.log for SQL errors"
        return 1
    fi
    
    if [ "$telemetry_count" -eq "0" ]; then
        log_warning "‚ö†Ô∏è  No telemetry attributes found. Adding essential telemetry..."
        # Add minimal telemetry to ensure adoption plans work
        docker exec -i "$DB_CONTAINER" psql -U postgres -d dap -c "
            INSERT INTO \"TelemetryAttribute\" (id, \"taskId\", name, description, \"dataType\", \"isRequired\", \"successCriteria\", \"order\", \"isActive\", \"createdAt\", \"updatedAt\") VALUES
            ('tel-sample-1', 'task-fw-001', 'sample_metric', 'Sample telemetry for adoption plans', 'NUMBER', true, '{\"operator\": \">=\", \"value\": 1}', 1, true, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            ON CONFLICT (id) DO NOTHING;
        " >/dev/null 2>&1
    fi
    
    # Step 3: Get actual customer product and solution IDs from database
    log_info "üìã Fetching customer assignments from database..."
    local cp_ids=($(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT id FROM \"CustomerProduct\" ORDER BY id;" 2>/dev/null | tr -d ' ' | grep -v '^$'))
    local cs_ids=($(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT id FROM \"CustomerSolution\" ORDER BY id;" 2>/dev/null | tr -d ' ' | grep -v '^$'))
    
    if [ ${#cp_ids[@]} -eq 0 ] && [ ${#cs_ids[@]} -eq 0 ]; then
        log_error "‚ùå No customer product or solution assignments found in database."
        return 1
    fi
    
    if [ ${#cp_ids[@]} -gt 0 ]; then
        log_info "üìã Found ${#cp_ids[@]} customer product assignments: ${cp_ids[*]}"
    fi
    if [ ${#cs_ids[@]} -gt 0 ]; then
        log_info "üì¶ Found ${#cs_ids[@]} customer solution assignments: ${cs_ids[*]}"
    fi
    
    # Step 4: Create adoption plans with retry logic
    local plans_created=0
    local plans_existed=0
    local solution_plans_created=0
    local solution_plans_existed=0
    
    # Create product adoption plans
    for cp_id in "${cp_ids[@]}"; do
        log_info "   üîÑ Processing product adoption plan for $cp_id..."
        
        local retry_attempts=3
        local retry=1
        local success=false
        
        while [ $retry -le $retry_attempts ] && [ "$success" = false ]; do
            if [ $retry -gt 1 ]; then
                log_info "     üîÑ Retry attempt $retry for $cp_id..."
                sleep 3
            fi
            
            local response=$(curl -s -X POST \
                -H "Content-Type: application/json" \
                -H "Authorization: admin" \
                -d "{\"query\": \"mutation { createAdoptionPlan(customerProductId: \\\"$cp_id\\\") { id totalTasks completedTasks progressPercentage } }\"}" \
                "$backend_url" 2>/dev/null)
            
            # Check for successful creation
            if echo "$response" | jq -e '.data.createAdoptionPlan.id' >/dev/null 2>&1; then
                local adoption_id=$(echo "$response" | jq -r '.data.createAdoptionPlan.id')
                local total_tasks=$(echo "$response" | jq -r '.data.createAdoptionPlan.totalTasks')
                log_success "     ‚úÖ Created product adoption plan $adoption_id with $total_tasks tasks"
                plans_created=$((plans_created + 1))
                success=true
                
            # Check if already exists
            elif echo "$response" | grep -q "already exists\|Adoption plan already exists"; then
                log_info "     ‚ÑπÔ∏è  Product adoption plan already exists for $cp_id"
                plans_existed=$((plans_existed + 1))
                success=true
                
            # Handle errors
            else
                log_warning "     ‚ö†Ô∏è  Attempt $retry failed for $cp_id"
                if [ $retry -eq $retry_attempts ]; then
                    log_error "     ‚ùå All retry attempts failed for $cp_id"
                    echo "Response: $response" | head -3
                fi
            fi
            
            retry=$((retry + 1))
        done
    done
    
    # Create solution adoption plans
    for cs_id in "${cs_ids[@]}"; do
        log_info "   üîÑ Processing solution adoption plan for $cs_id..."
        
        local retry_attempts=3
        local retry=1
        local success=false
        
        while [ $retry -le $retry_attempts ] && [ "$success" = false ]; do
            if [ $retry -gt 1 ]; then
                log_info "     üîÑ Retry attempt $retry for $cs_id..."
                sleep 3
            fi
            
            local response=$(curl -s -X POST \
                -H "Content-Type: application/json" \
                -H "Authorization: admin" \
                -d "{\"query\": \"mutation { createSolutionAdoptionPlan(customerSolutionId: \\\"$cs_id\\\") { id totalTasks completedTasks progressPercentage } }\"}" \
                "$backend_url" 2>/dev/null)
            
            # Check for successful creation
            if echo "$response" | jq -e '.data.createSolutionAdoptionPlan.id' >/dev/null 2>&1; then
                local adoption_id=$(echo "$response" | jq -r '.data.createSolutionAdoptionPlan.id')
                local total_tasks=$(echo "$response" | jq -r '.data.createSolutionAdoptionPlan.totalTasks')
                log_success "     ‚úÖ Created solution adoption plan $adoption_id with $total_tasks tasks"
                solution_plans_created=$((solution_plans_created + 1))
                success=true
                
            # Check if already exists
            elif echo "$response" | grep -q "already exists\|Solution adoption plan already exists"; then
                log_info "     ‚ÑπÔ∏è  Solution adoption plan already exists for $cs_id"
                solution_plans_existed=$((solution_plans_existed + 1))
                success=true
                
            # Handle errors
            else
                log_warning "     ‚ö†Ô∏è  Attempt $retry failed for $cs_id"
                if [ $retry -eq $retry_attempts ]; then
                    log_error "     ‚ùå All retry attempts failed for $cs_id"
                    echo "Response: $response" | head -3
                fi
            fi
            
            retry=$((retry + 1))
        done
    done
    
    # Step 5: Final verification and summary
    sleep 2
    local final_product_plans=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"AdoptionPlan\";" 2>/dev/null | tr -d ' ')
    local final_solution_plans=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"SolutionAdoptionPlan\";" 2>/dev/null | tr -d ' ')
    local final_tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerTask\";" 2>/dev/null | tr -d ' ')
    local final_solution_tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerSolutionTask\";" 2>/dev/null | tr -d ' ')
    local final_telemetry=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"CustomerTelemetryAttribute\";" 2>/dev/null | tr -d ' ')
    
    echo ""
    log_success "üéâ Adoption Plan Creation Complete!"
    log_info "üìä Product Plans:"
    log_info "  üÜï Newly Created: $plans_created"
    log_info "  üìã Already Existed: $plans_existed"
    log_info "  üìä Total: $final_product_plans"
    log_info "üì¶ Solution Plans:"
    log_info "  üÜï Newly Created: $solution_plans_created"
    log_info "  üìã Already Existed: $solution_plans_existed"
    log_info "  üìä Total: $final_solution_plans"
    log_info "‚öôÔ∏è  Tasks:"
    log_info "  üìã Customer Product Tasks: $final_tasks"
    log_info "  üì¶ Customer Solution Tasks: $final_solution_tasks"
    log_info "  üìà Telemetry Attributes: $final_telemetry"
    
    local total_expected=$((${#cp_ids[@]} + ${#cs_ids[@]}))
    local total_actual=$((final_product_plans + final_solution_plans))
    
    if [ $total_actual -eq $total_expected ]; then
        echo ""
        log_success "‚úÖ SUCCESS: All $total_actual adoption plans created successfully!"
        log_success "üöÄ Complete sample data ready for testing and demonstrations!"
        
        # Show detailed breakdown
        echo ""
        log_info "üìã Customer Adoption Plan Details:"
        docker exec $DB_CONTAINER psql -U postgres -d dap -c "
            SELECT 
                c.name as \"Customer\",
                p.name as \"Product\", 
                ap.\"totalTasks\" as \"Tasks\"
            FROM \"AdoptionPlan\" ap
            JOIN \"CustomerProduct\" cp ON ap.\"customerProductId\" = cp.id
            JOIN \"Customer\" c ON cp.\"customerId\" = c.id
            JOIN \"Product\" p ON cp.\"productId\" = p.id
            ORDER BY c.name, p.name;
        " 2>/dev/null | grep -v "^$"
        
    else
        echo ""
        log_warning "‚ö†Ô∏è  Only $final_plans out of ${#cp_ids[@]} adoption plans were created."
        log_info "üí° You can create missing plans manually in the frontend or run this command again."
    fi
}

# Remove sample data while preserving user-created data
reset_sample_data() {
    log_info "Removing sample data while preserving user-created data..."
    
    # Check if database container is running
    if [ -z "$DB_CONTAINER" ]; then
        log_error "No database container found. Run '$0 start' first."
        exit 1
    fi
    
    if ! docker ps --format "{{.Names}}" | grep -q "^${DB_CONTAINER}$"; then
        log_error "Database container '$DB_CONTAINER' is not running. Run '$0 start' first."
        exit 1
    fi
    
    # Check if remove-sample-data.sql exists
    if [ ! -f "$PROJECT_DIR/remove-sample-data.sql" ]; then
        log_error "‚ùå remove-sample-data.sql not found. This script is required for selective sample data removal."
        exit 1
    fi
    
    # Execute the sample data removal script
    log_info "üóëÔ∏è Removing sample data (preserving user data)..."
    if docker exec -i "$DB_CONTAINER" psql -U postgres -d dap < "$PROJECT_DIR/remove-sample-data.sql"; then
        echo ""
        log_success "‚úÖ Sample data removed successfully!"
        
        # Show remaining data
        local products=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Product\" WHERE \"deletedAt\" IS NULL;" 2>/dev/null | tr -d ' ')
        local tasks=$(docker exec $DB_CONTAINER psql -U postgres -d dap -t -c "SELECT COUNT(*) FROM \"Task\" WHERE \"deletedAt\" IS NULL;" 2>/dev/null | tr -d ' ')
        
        echo ""
        log_info "üìä Removed sample products (if they existed):"
        log_info "  ‚Ä¢ prod-cisco-duo (Cisco Duo MFA)"
        log_info "  ‚Ä¢ prod-cisco-sdwan (Cisco SD-WAN)"
        log_info "  ‚Ä¢ prod-cisco-firewall (Cisco Secure Firewall)"
        log_info "  ‚Ä¢ prod-cisco-ise (Cisco ISE)"
        log_info "  ‚Ä¢ prod-cisco-secure-access-sample (Cisco Secure Access Sample)"
        log_info "  ‚Ä¢ prod-sdwan-platform (SD-WAN Platform)"
        log_info "  ‚Ä¢ prod-cloud-security (Cloud Security Platform)"
        echo ""
        log_info "üìä Removed ALL customer adoption data:"
        log_info "  ‚Ä¢ All customer product assignments"
        log_info "  ‚Ä¢ All adoption plans"
        log_info "  ‚Ä¢ All customer tasks and telemetry"
        log_info "  ‚Ä¢ Customer solutions for sample products"
        echo ""
        log_info "üìä Remaining database contains:"
        log_info "  üì¶ $products Products (user-created)"
        log_info "  üìã $tasks Tasks (user-created)"
        log_info "  üë• Customers (preserved, but unassigned)"
        echo ""
        log_info "‚úÖ Ready for fresh customer assignments!"
    else
        log_error "‚ùå Failed to remove sample data"
        exit 1
    fi
    
    log_info "üîÑ Refresh your browser to see the updated data!"
}

# Show help
show_help() {
    echo -e "${PURPLE}DAP Application Manager${NC}"
    echo ""
    echo "All-in-one script to manage the DAP application lifecycle."
    echo ""
    echo "Usage: $0 [command]"
    echo ""
    echo "Commands:"
    echo -e "  ${GREEN}start${NC}         - Start all application services"
    echo -e "  ${RED}stop${NC}          - Stop all application services" 
    echo -e "  ${YELLOW}restart${NC}       - Restart all services (keeps existing data)"
    echo -e "  ${CYAN}clean-restart${NC} - ‚ö†Ô∏è  WIPES ALL DATA, then loads fresh sample data"
    echo -e "  ${BLUE}add-sample${NC}    - ‚úÖ Add sample data (preserves existing user data)"
    echo -e "  ${PURPLE}reset-sample${NC}  - ‚úÖ Remove sample data only (preserves user data)"
    echo -e "  ${PURPLE}test${NC}          - Run comprehensive end-user test suite"
    echo -e "  ${BLUE}status${NC}        - Show status of all services and data"
    echo -e "  ${PURPLE}help${NC}          - Show this help message"
    echo ""
    echo "Examples:"
    echo "  $0 start           # Start for daily development"
    echo "  $0 add-sample      # ‚úÖ Add sample data (preserves your data)"
    echo "  $0 reset-sample    # ‚úÖ Remove sample data (preserves your data)"
    echo "  $0 clean-restart   # ‚ö†Ô∏è  DANGER: Wipes everything, fresh start"
    echo "  $0 test            # Validate all functionality with comprehensive test"
    echo "  $0 status          # Check what's running"
    echo "  $0 stop            # End development session"
    echo ""
    echo "Components managed:"
    echo "  ‚Ä¢ PostgreSQL Database (Docker container)"
    echo "  ‚Ä¢ Backend GraphQL API (Node.js on port $BACKEND_PORT)"
    echo "  ‚Ä¢ Frontend React App (Vite on port $FRONTEND_PORT)"
    echo ""
    echo "The clean-restart command provides:"
    echo "  ‚Ä¢ 5 comprehensive products with mandatory attributes"
    echo "  ‚Ä¢ 2 solution bundles (Security, Digital Transformation)"
    echo "  ‚Ä¢ Tasks with howToDoc and howToVideo fields"
    echo "  ‚Ä¢ Complete data relationships and constraints"
    echo "  ‚Ä¢ Essential licenses, outcomes, and releases for each product"
    echo "  ‚Ä¢ Customer solution assignments and adoption tracking"
    echo ""
    echo "Sample data management:"
    echo "  ‚Ä¢ add-sample: ‚úÖ RECOMMENDED - Adds sample data, preserves your existing data"
    echo "  ‚Ä¢ reset-sample: ‚úÖ SAFE - Removes only sample data, keeps your products/customers"
    echo "  ‚Ä¢ clean-restart: ‚ö†Ô∏è  DESTRUCTIVE - Wipes EVERYTHING (use only for complete reset)"
    echo ""
    echo "‚ö†Ô∏è  IMPORTANT: clean-restart deletes ALL data including manually created products!"
    echo "   To preserve your 'Cisco Secure Access' or other custom data, use 'add-sample' instead."
    echo ""
    echo "The test command runs comprehensive validation:"
    echo "  ‚Ä¢ Simulates complete end-user workflows"
    echo "  ‚Ä¢ Tests all CRUD operations and business logic"
    echo "  ‚Ä¢ Verifies database persistence and relationships"
    echo "  ‚Ä¢ Validates mandatory attributes and constraints"
    echo "  ‚Ä¢ Ensures frontend ‚Üî backend ‚Üî database integration"
}

# Main script logic
main() {
    # Change to project directory
    cd "$PROJECT_DIR"
    
    case "${1:-}" in
        start)
            start_all
            ;;
        stop)
            stop_all
            ;;
        restart)
            restart_all
            ;;
        clean-restart)
            clean_restart
            ;;
        add-sample)
            add_sample_data
            ;;
        reset-sample)
            reset_sample_data
            ;;
        test)
            run_comprehensive_test
            ;;
        status)
            show_status
            ;;
        help|--help|-h)
            show_help
            ;;
        *)
            if [ -n "${1:-}" ]; then
                log_error "Unknown command: $1"
                echo ""
            fi
            show_help
            ;;
    esac
}

# Check if script is run with sudo (not recommended)
if [ "$EUID" -eq 0 ]; then
    log_warning "Running as root is not recommended. Consider running as a regular user."
fi

# Run main function with all arguments
main "$@"